{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Paso1_Analisis_de_Texto_para_Spam Avance1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZYjeFl20oa5",
        "colab_type": "text"
      },
      "source": [
        "# 0. Instalacion de utilitarios Pyspark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6zaa4yk0uIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.3.4/spark-2.3.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.4-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0SmG6708QQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyor71X98igS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRsVKjDvsmoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsNTQa-qsr7j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e90d8643-b6ed-48e0-a959-b476618d39d6"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 53kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 42.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=a5057c1fd71f5a4945c3797b45a38dda1c2a1dd9d4bc590a6a3dfb7eef25ea42\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCKm2w9rswTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext\n",
        "spark = SparkSession.builder.master(\"local\").getOrCreate()\n",
        "sc = SparkContext.getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXie2Umg1DZk",
        "colab_type": "text"
      },
      "source": [
        "# 1. Lectura del origen datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-l6Pu6f1HO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lectura desde un archivo fisico\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZL0PhM88Eys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "fa1e26cc-f860-41e0-892f-eb097bb47bc6"
      },
      "source": [
        "\n",
        "# Conexion al drive\n",
        "#---------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZQDnxtq2G2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e15e6d25-d248-4419-d645-9b3a23a4ffa4"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/        \u001b[01;34mspark-2.3.4-bin-hadoop2.7\u001b[0m/     \u001b[01;34mspark-2.4.4-bin-hadoop2.7\u001b[0m/\n",
            "\u001b[01;34msample_data\u001b[0m/  spark-2.3.4-bin-hadoop2.7.tgz  spark-2.4.4-bin-hadoop2.7.tgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltZocWSm2l9G",
        "colab_type": "text"
      },
      "source": [
        "#2.  Cargando los datos en formato Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg8zoYu62uhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DS_spam = spark.read.csv('/content/drive/My Drive/PySpark Machine Learning en plataforma Big Data/Training R ML en Casos de Negocios/9_Analisis_texto_Spam_emaling/Identificando_correos_spam_vf.csv', sep=';', header=True, inferSchema=True)\n",
        "\n",
        "# 2.1 Revision de formatos \n",
        "DS_spam.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DevCxW045s4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dimensiona de base\n",
        "print((DS_spam.count(),len(DS_spam.columns)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBEt1wHV2Zy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2.2 Revisiones  \n",
        "DS_spam.show(5, truncate = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpYnf-WM3iun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2.3 Validacion de carga del total de registros\n",
        "print(DS_spam.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J1Stx2j9KdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2.4 Exploracion inicial\n",
        "DS_spam.describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UavJB8AASDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2.5 Los casos de Spam\n",
        "DS_spam.groupBy('clase').count().show(10,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz0d6ySecPO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2.6 Filtrando los casos a analizar \n",
        "DS_spam_2=DS_spam.filter(DS_spam[\"Clase\"]>=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPGDzwTKcr17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2.7 Validacion\n",
        "DS_spam_2.groupBy('clase').count().show(10,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjgOU2xcB-cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Revision de los valores\n",
        "DS_spam_2.show(5, truncate = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb68mHt9ECfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creando la columna distancia\n",
        "from pyspark.sql.functions import length,rand \n",
        "DS_spam_2=DS_spam_2.withColumn('length',length(DS_spam['texto'])) \n",
        "DS_spam_2.orderBy(rand()).show(10,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awuIpWlZEuhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cantidad de texto\n",
        "DS_spam_2.groupBy('clase').agg({'Length':'mean'}).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY1yxRAc4-qT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DS_spam_2.groupBy('clase').agg({'Length':'median'}).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jev3Q93elrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Revision preliminar de los comentarios\n",
        "from pyspark.sql.functions import rand\n",
        "DS_spam_2.orderBy(rand()).show(10,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSzXn2nll1Ak",
        "colab_type": "text"
      },
      "source": [
        "# 2.  Realizando la codificación de los emaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S8_1GllFT9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer\n",
        "from pyspark.ml.feature import StopWordsRemover\n",
        "tokenization=Tokenizer(inputCol='texto',outputCol='tokens')\n",
        "tokenized_df=tokenization.transform(DS_spam_2)\n",
        "stopword_removal=StopWordsRemover(inputCol='tokens', outputCol='refined_tokens')\n",
        "refined_text_df=stopword_removal.transform(tokenized_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csjs-ZQumMYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "refined_text_df.orderBy(rand()).show(10,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0ci-vMTmsMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Conteo de las palabras\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import *\n",
        "len_udf = udf(lambda s: len(s), IntegerType())\n",
        "refined_text_df = refined_text_df.withColumn(\"token_count\",\n",
        "len_udf(col('refined_tokens')))\n",
        "refined_text_df.orderBy(rand()).show(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a-P4gxspQuz",
        "colab_type": "text"
      },
      "source": [
        "# 4.  Preparando la información para el modelamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2f0Nba2FTm5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z8XOpyHpWG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creando las variables nevesarias para el modelamiento\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "\n",
        "count_vec=CountVectorizer(inputCol='refined_tokens',outputCol='features')\n",
        "cv_text_df=count_vec.fit(refined_text_df).transform(refined_text_df)\n",
        "cv_text_df.select(['refined_tokens','token_count','features','Clase']).show(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz8GfKyyp5wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Variables propias para el modelamiento\n",
        "\n",
        "model_text_df=cv_text_df.select(['features','token_count','Clase'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYOqa3EZqOVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Consolidadno toda la información codificada del mensaje en los correos\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "df_assembler = VectorAssembler(inputCols=['features','token_count'],outputCol='features_vec')\n",
        "model_text_df = df_assembler.transform(model_text_df)\n",
        "model_text_df.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwqEYPk8shGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adecuando el formato de la variable Clase a numerica\n",
        "from pyspark.sql.types import IntegerType\n",
        "model_text_df = model_text_df.withColumn(\"Clase\", model_text_df[\"Clase\"].cast(IntegerType()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfLXT0IvssLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_text_df.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdGWun_NqafO",
        "colab_type": "text"
      },
      "source": [
        "# 5.  Seleccionando la muestra de aprendizaje y validacion\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhTiyCtfqeQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_df,test_df=model_text_df.randomSplit([0.75,0.25],seed=1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btVmyVnCqkek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_df.groupBy('Clase').count().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGz9jdCuqtxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.groupBy('Clase').count().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwY0WR5yqyby",
        "colab_type": "text"
      },
      "source": [
        "# 6.  Modelamiento de predictivo de texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fg8NDvirLLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "log_reg=LogisticRegression(featuresCol='features_vec',labelCol='Clase').fit(training_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkUMGTXwtGqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results=log_reg.evaluate(test_df).predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpco1EdKtJHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results.show(10,truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX8pFRFzxNkJ",
        "colab_type": "text"
      },
      "source": [
        "# 7. Evaluacion del modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63Nh0Z77xsVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "trainingSummary = log_reg.summary\n",
        "roc = trainingSummary.roc.toPandas()\n",
        "plt.plot(roc['FPR'],roc['TPR'])\n",
        "plt.ylabel('False Positive Rate')\n",
        "plt.xlabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()\n",
        "print('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}