{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IA_Saturdays_Day_7_Python_bootcamp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkHezUSPjoCF",
        "colab_type": "text"
      },
      "source": [
        "# **Python for data science and data analysis from scratch**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6Ltbd-RjOOi",
        "colab_type": "text"
      },
      "source": [
        "Para esta sesión utilizaremos las siguientes librerías:\n",
        "\n",
        "**numpy**\n",
        "\n",
        "**scikit-learn**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**imutils**\n",
        "\n",
        "Librería de código abierto con operaciones básicas para manipulación de imágenes: [imutils](https://www.pyimagesearch.com/2015/02/02/just-open-sourced-personal-imutils-package-series-opencv-convenience-functions/)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**opencv**\n",
        "\n",
        "Librería especializada para visión por computadora en tiempo real, soporta C++, Java y Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRx4sTndk0lo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Para esta sesión vamos a buscar anomalías en imágenes.\n",
        "\n",
        "Una anomalía se define como un evento que se desvía de lo estándar, que pasa raramente o que no sigue un patrón.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KJnuidXzXjF",
        "colab_type": "text"
      },
      "source": [
        "Ejemplos de anomalías incluyen:\n",
        "\n",
        "* Picos marcados en la bolsa de valores debido a eventos mundiales.\n",
        "* Productos defectuosos en una línea de ensamble.\n",
        "* Muestras contaminadas en un laboratorio.\n",
        "\n",
        "En una gráfica de distribución normal, las anomalías existen en los extremos.\n",
        "\n",
        "![bell-curve](https://analyticstraining.com/wp-content/uploads/2013/01/bell-curve.png)\n",
        "\n",
        "\n",
        "Estos eventos van a ocurrir, pero en una proporción mucho menor.\n",
        "\n",
        "Para los algoritmos de aprendizaje automático esto es considerado un problema difícil, porque tendremos muchos ejemplos de eventos normales y pocos anormales.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0U-iUubyes_",
        "colab_type": "text"
      },
      "source": [
        "## Algoritmos de detección de anomalías\n",
        "\n",
        "![anomaly](https://pyimagesearch.com/wp-content/uploads/2020/01/intro_anomaly_detection_plot.png)\n",
        "\n",
        "La detección de anomalías puede ser dividida en dos subclases principales:\n",
        "\n",
        "\n",
        "*   **Detección de outliers o valores extremos**: El dataset de entrada contiene ejemplos de eventos normales y anormales. Estos algoritmos buscan ajustar regiones de los datos de entrenamiento donde los eventos estándar están más concentrados, sin tener en cuenta o aislando los eventos de anomalías. Dichos algoritmos a menudo se entrenan de manera no supervisada (es decir, sin etiquetas). A veces utilizamos estos métodos para ayudar a limpiar y pre-procesar conjuntos de datos antes de aplicar técnicas adicionales de aprendizaje automático.\n",
        "\n",
        "*   **Detección de novedad**: A diferencia de la detección de valores atípicos, que incluye ejemplos de eventos estándar y de anomalía, los algoritmos de detección de novedad solo tienen los puntos de datos de eventos estándar (es decir, sin eventos de anomalías) durante el tiempo de entrenamiento. Durante el entrenamiento, proporcionamos a estos algoritmos ejemplos etiquetados de eventos estándar (aprendizaje supervisado). En el momento de la prueba / predicción, los algoritmos de detección de novedad deben detectar cuando un punto de datos de entrada es atípico.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swYDZa-4SskU",
        "colab_type": "text"
      },
      "source": [
        "## Bosques de aislamiento para detección de anomalías\n",
        "\n",
        "En esta sesión usaremos el algoritmo de Isolation Forests, el cual es un tipo de algoritmo de conjunto y consiste en múltiples árboles de decisión utilizados para dividir el conjunto de datos de entrada en distintos grupos de elementos internos.\n",
        "\n",
        "Como se muestra en la figura, los Bosques de Aislamiento aceptan un conjunto de datos de entrada (puntos blancos) y luego construyen una variedad que los rodea.\n",
        "\n",
        "![isolation forest](https://pyimagesearch.com/wp-content/uploads/2020/01/intro_anomaly_detection_isolation_forest.png)\n",
        "\n",
        "En el momento de la prueba, el bosque de aislamiento puede determinar si los puntos de entrada caen dentro de la mayoría (eventos estándar, puntos verdes) o fuera del área de alta densidad (eventos de anomalías, puntos rojos).\n",
        "\n",
        "Para más teoría acerca de este algoritmo tenemos el siguiente [artículo](https://medium.com/@keepler.io/isolation-forest-el-algoritmo-estrella-para-detecci%C3%B3n-de-anomal%C3%ADas-416bb5892f10)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtGABTiQUEzQ",
        "colab_type": "text"
      },
      "source": [
        "## Configurar el entorno de desarrollo de detección de anomalías\n",
        "\n",
        "Primero, necesitamos bajar el código para nuestra aplicación: [code.zip](https://drive.google.com/file/d/1Iv-mqwfL5bXxhmT4dN32QW3Bg_Khm_AY/view?usp=sharing)\n",
        "\n",
        "Usando la terminal entramos al directorio y creamos un entorno virtual con el comando: \n",
        "\n",
        "```\n",
        "python3 -m venv env\n",
        "```\n",
        "Después activamos nuestro entorno virtual con:\n",
        "\n",
        "\n",
        "```\n",
        "source env/bin/activate\n",
        "```\n",
        "\n",
        "Ahora, vamos a instalar los paquetes necesarios para la aplicación:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "pip install numpy\n",
        "pip install opencv-contrib-python\n",
        "pip install imutils\n",
        "pip install scikit-learn\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxX0xHgQaIaC",
        "colab_type": "text"
      },
      "source": [
        "Dentro de la carpeta *pyimagesearch* se encuentra el archivo **features.py**. Este script contiene dos funciones responsables de cargar las imágenes de nuestro dataset del disco y calcular el histograma para cada imagen.\n",
        "\n",
        "![histograma](https://www.researchgate.net/profile/Jose_Antonio_Taquia_Gutierrez/publication/322016396/figure/fig6/AS:668393673867271@1536368878493/Figura-7-Histograma-de-color-Imagen-A.png)\n",
        "\n",
        "Como en algoritmos anteriores, tendremos una fase de entrenamiento y otra de prueba.\n",
        "\n",
        "El archivo de **train_anomaly_detector.py** calcula los atributos y entrena el modelo de Isolation Forest para detectar anomalías, el resultado se guarda como anomaly_detector.model.\n",
        "\n",
        "La siguiente parte es el script de **test_anomaly_detector.py**, el cual lee una imagen y determina si es o no una anomalía.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGHa6LpsbkNY",
        "colab_type": "text"
      },
      "source": [
        "## Implementación de las funciones auxiliares de extracción de características\n",
        "\n",
        "Antes de que podamos entrenar un modelo de aprendizaje automático para detectar anomalías y valores atípicos, primero debemos definir un proceso para cuantificar y caracterizar los contenidos de nuestras imágenes de entrada.\n",
        "\n",
        "Para lograr esta tarea, utilizaremos histogramas de color.\n",
        "\n",
        "Los histogramas de color son métodos simples pero efectivos para caracterizar la distribución de color de una imagen.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aIOI4PBjm7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import cv2\n",
        "def quantify_image(image, bins=(4, 6, 3)):\n",
        "\t# compute a 3D color histogram over the image and normalize it\n",
        "\thist = cv2.calcHist([image], [0, 1, 2], None, bins,\n",
        "\t\t[0, 180, 0, 256, 0, 256])\n",
        "\thist = cv2.normalize(hist, hist).flatten()\n",
        "\t# return the histogram\n",
        "\treturn hist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p8Z-lBAcU-l",
        "colab_type": "text"
      },
      "source": [
        "Para aprender más acerca de image processing y computer vision tenemos esta página: [www.pyimagesearch.com](https://www.pyimagesearch.com/practical-python-opencv/).\n",
        "\n",
        "La siguiente función maneja dos cosas:\n",
        "\n",
        "* Aceptar la ruta a un directorio que contiene el dataset de imágenes.\n",
        "\n",
        "* Recorre las imágenes del directorio y llama el método de quantify_image para procesarlas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-NuOtlromGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(datasetPath, bins):\n",
        "\t# grab the paths to all images in our dataset directory, then\n",
        "\t# initialize our lists of images\n",
        "\timagePaths = list(paths.list_images(datasetPath))\n",
        "\tdata = []\n",
        "\t# loop over the image paths\n",
        "\tfor imagePath in imagePaths:\n",
        "\t\t# load the image and convert it to the HSV color space\n",
        "\t\timage = cv2.imread(imagePath)\n",
        "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\t\t# quantify the image and update the data list\n",
        "\t\tfeatures = quantify_image(image, bins)\n",
        "\t\tdata.append(features)\n",
        "\t# return our data list as a NumPy array\n",
        "\treturn np.array(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76EuqY4xdlvW",
        "colab_type": "text"
      },
      "source": [
        "## Implementar el script de entrenamiento de detección de anomalías con scikit-learn\n",
        "\n",
        "Con nuestras funciones de ayuda implementadas, ahora podemos pasar a entrenar un modelo de detección de anomalías.\n",
        "\n",
        "Como se mencionó anteriormente en esta sesión, utilizaremos un bosque de aislamiento para ayudar a determinar los puntos de datos de anomalías / novedades.\n",
        "\n",
        "Nuestra implementación de Bosques de aislamiento proviene de la biblioteca [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKW4M0JxyAyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from pyimagesearch.features import load_dataset\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import argparse\n",
        "import pickle\n",
        "# construct the argument parser and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
        "\thelp=\"path to dataset of images\")\n",
        "ap.add_argument(\"-m\", \"--model\", required=True,\n",
        "\thelp=\"path to output anomaly detection model\")\n",
        "args = vars(ap.parse_args())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQez8rq9eKVN",
        "colab_type": "text"
      },
      "source": [
        "Ahora, podemos entrenar nuestro modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD-nBn_poEMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load and quantify our image dataset\n",
        "print(\"[INFO] preparing dataset...\")\n",
        "data = load_dataset(args[\"dataset\"], bins=(3, 3, 3))\n",
        "# train the anomaly detection model\n",
        "print(\"[INFO] fitting anomaly detection model...\")\n",
        "model = IsolationForest(n_estimators=100, contamination=0.01,\n",
        "\trandom_state=42)\n",
        "model.fit(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYPntD1PlFs2",
        "colab_type": "text"
      },
      "source": [
        "Después de entrenar nuestro modelo, se guarda en disco:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOM2XKfZfZSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# serialize the anomaly detection model to disk\n",
        "f = open(args[\"model\"], \"wb\")\n",
        "f.write(pickle.dumps(model))\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLCzCOCKfT-r",
        "colab_type": "text"
      },
      "source": [
        "## Entrenar el detector de anomalías\n",
        "\n",
        "Vamos a correr el siguiente comando desde nuestra terminal:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "python train_anomaly_detector.py --dataset forest --model anomaly_detector.model\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s119UxJQf9O3",
        "colab_type": "text"
      },
      "source": [
        "## Probar el detector de anomalías\n",
        "\n",
        "El siguiente script **test_anomaly_detector.py** carga el modelo que creamos en el paso anterior.\n",
        "\n",
        "Carga, pre-procesa y cuantifica una imagen de prueba.\n",
        "\n",
        "Hace una predicción para determinar si la imagen es un bosque o no (una anomalía).\n",
        "\n",
        "Muestra el resultado:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab25MtEJhVGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from pyimagesearch.features import quantify_image\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "# construct the argument parser and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-m\", \"--model\", required=True,\n",
        "\thelp=\"path to trained anomaly detection model\")\n",
        "ap.add_argument(\"-i\", \"--image\", required=True,\n",
        "\thelp=\"path to input image\")\n",
        "args = vars(ap.parse_args())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhUJxY75hiKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the anomaly detection model\n",
        "print(\"[INFO] loading anomaly detection model...\")\n",
        "model = pickle.loads(open(args[\"model\"], \"rb\").read())\n",
        "# load the input image, convert it to the HSV color space, and\n",
        "# quantify the image in the *same manner* as we did during training\n",
        "image = cv2.imread(args[\"image\"])\n",
        "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "features = quantify_image(hsv, bins=(3, 3, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWeOxl11hixb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use the anomaly detector model and extracted features to determine\n",
        "# if the example image is an anomaly or not\n",
        "preds = model.predict([features])[0]\n",
        "label = \"anomaly\" if preds == -1 else \"normal\"\n",
        "color = (0, 0, 255) if preds == -1 else (0, 255, 0)\n",
        "# draw the predicted label text on the original image\n",
        "cv2.putText(image, label, (10,  25), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "\t0.7, color, 2)\n",
        "# display the image\n",
        "cv2.imshow(\"Output\", image)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOKWgGcJhv6s",
        "colab_type": "text"
      },
      "source": [
        "Para correr la prueba usamos el comando:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "python test_anomaly_detector.py --model anomaly_detector.model --image examples/forest_cdmc290.jpg \n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dulk3MY1h4cS",
        "colab_type": "text"
      },
      "source": [
        "**Ejercicio**\n",
        "\n",
        "Probar el algoritmo con otro dataset para ver si es capaz de detectar anomalías. \n",
        "\n",
        "Por ejemplo con el siguiente dataset de [hacker rank](https://www.hackerrank.com/challenges/digital-camera-day-or-night/problem).\n",
        "\n",
        "En qué otros escenarios puede servir nuestro modelo? Detectar animales perros/gatos, ciudad/provincia, etc.?"
      ]
    }
  ]
}