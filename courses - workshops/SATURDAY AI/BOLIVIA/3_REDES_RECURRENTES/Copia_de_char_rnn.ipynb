{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de char_rnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVp4KMUU8vh-"
      },
      "source": [
        "# Clasificación de apellidos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxcRBA9n8Zh5",
        "outputId": "cb174be5-a972-4b0f-87c8-a0e302546ca4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7au8ENy84xb"
      },
      "source": [
        "# Transformar Unicode a ASCII, función de https://stackoverflow.com/a/518232/2809427\n",
        "\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "all_letters = string.ascii_letters + \" .:;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "  return ''.join(\n",
        "      c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn'\n",
        "      and c in all_letters\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb68hne89KEZ"
      },
      "source": [
        "print(unicodeToAscii('Ślusàrski'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuWyf9PO9dbz"
      },
      "source": [
        "# Funciones para leer los ficheros\n",
        "\n",
        "import glob\n",
        "\n",
        "def findFiles(path):\n",
        "  return glob.glob(path)\n",
        "\n",
        "def readLines(filename):\n",
        "  lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "  return [unicodeToAscii(line) for line in lines]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXK8PTlz90sk"
      },
      "source": [
        "# Creamos un diccionario para el dataset\n",
        "\n",
        "import os\n",
        "\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "\n",
        "PATH = 'drive/MyDrive/Saturdays.AI/names/*.txt'\n",
        "\n",
        "for filename in findFiles(PATH):\n",
        "  category = os.path.splitext(os.path.basename(filename))[0]\n",
        "  all_categories.append(category)\n",
        "  lines = readLines(filename)\n",
        "  category_lines[category] = lines\n",
        "\n",
        "n_categories = len(all_categories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNIVaRt3-HJS"
      },
      "source": [
        "# Vamos a ver el dataset\n",
        "\n",
        "##########"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaL_knfo-h2k"
      },
      "source": [
        "# De carácteres a vectores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOvG3IKq-KhH"
      },
      "source": [
        "# Cear un indice para cada letra\n",
        "\n",
        "#########"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E6BTrGD-q2k"
      },
      "source": [
        "print(letterToIndex('h'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41wv9GfA-w7D"
      },
      "source": [
        "# Convertir una letra en un tensor <1 x n_letras>\n",
        "\n",
        "import torch\n",
        "\n",
        "def letterToTensor(letter):\n",
        "  #######\n",
        "  return tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbTlK0EE-4IC"
      },
      "source": [
        "# Vamos a ver el tensor de una letra\n",
        "\n",
        "######"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9IoBCsx_F-a"
      },
      "source": [
        "# Convertir un string en un tensor the hone-hot vectors de sus caracteres <len_string x 1 x n_letras>\n",
        "\n",
        "def lineToTensor(line):\n",
        "  tensor = torch.zeros(len(line), 1, n_letters)\n",
        "  for li, letter in enumerate(line):\n",
        "    tensor[li][0][letterToIndex(letter)] = 1\n",
        "  return tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY9GqpwMAkOF"
      },
      "source": [
        "print(lineToTensor('Jones').size())\n",
        "print(lineToTensor('Jones'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGa0wgerAprG"
      },
      "source": [
        "# Modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O8-gKCKAr0x"
      },
      "source": [
        "# Inicializar modelo\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "\n",
        "    ########\n",
        "  \n",
        "  def forward(self, input, hidden):\n",
        "\n",
        "    ##########\n",
        "    \n",
        "    return output, hidden\n",
        "  \n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, self.hidden_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrpBH0RVAxY4"
      },
      "source": [
        "# Parámetros\n",
        "\n",
        "n_hidden = 128\n",
        "\n",
        "#######"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYRaJ4LQA-w0"
      },
      "source": [
        "#input = letterToTensor('a')\n",
        "#output, next_hidden = rnn(input, hidden)\n",
        "\n",
        "#Mejor utilizar lineToTensor\n",
        "input = lineToTensor('Albert')\n",
        "\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "output, next_hidden = rnn(input[0], hidden)\n",
        "\n",
        "######"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht7tFP5PBTYg"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6P9Noh3BVot"
      },
      "source": [
        "# Función para entrenar\n",
        "\n",
        "loss_function = nn.NLLLoss()\n",
        "learning_rate = 0.005\n",
        "\n",
        "def train(category_tensor, line_tensor):\n",
        "\n",
        "  # Inicializar hidden layer\n",
        "  ####\n",
        "\n",
        "  # Inicializar gradients a 0\n",
        "  ######\n",
        "\n",
        "  for i in range(line_tensor.size()[0]):\n",
        "    output, hidden = rnn(line_tensor[i], hidden)\n",
        "  \n",
        "  #########\n",
        "\n",
        "  for p in rnn.parameters():\n",
        "    p.data.add_(p.grad.data, alpha=-learning_rate)\n",
        "  \n",
        "  return output, loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgKrs7V1BorV"
      },
      "source": [
        "# Función para escoger training examples\n",
        "\n",
        "import random\n",
        "\n",
        "def randomChoice(l):\n",
        "  return l[random.randint(0, len(l) - 1)]\n",
        "\n",
        "def randomTrainingExample():\n",
        "  category = randomChoice(all_categories)\n",
        "  line = randomChoice(category_lines[category])\n",
        "  category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "  line_tensor = lineToTensor(line)\n",
        "  return category, line, category_tensor, line_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVWIyT20CTBo"
      },
      "source": [
        "# Función para saber el tiempo de cada iteración\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVL8j1hACrIj"
      },
      "source": [
        "# Función para interpretar el output\n",
        "\n",
        "def categoryFromOutput(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item()\n",
        "    return all_categories[category_i], category_i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcZS4KRbBzX6"
      },
      "source": [
        "# Vamos a entrenar\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "n_iters = 100000\n",
        "print_every = 5000\n",
        "plot_every = 1000\n",
        "\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for iter in range(1, n_iters + 1):\n",
        "  #########\n",
        "\n",
        "  if iter % print_every == 0:\n",
        "      guess, guess_i = categoryFromOutput(output)\n",
        "      correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "      print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
        "\n",
        "  if iter % plot_every == 0:\n",
        "    all_losses.append(current_loss / plot_every)\n",
        "    current_loss = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_VxY7suCEtf"
      },
      "source": [
        "# Visualizar loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ODXwC-ODIyp"
      },
      "source": [
        "# Evaluar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDqMd8eoDGPb"
      },
      "source": [
        "# Evaluar\n",
        "\n",
        "def evaluate(line_tensor):\n",
        "\n",
        "  ########\n",
        "  \n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhQuT2W_DYXe"
      },
      "source": [
        "# Predicción\n",
        "\n",
        "def predict(input_line, n_predictions=3):\n",
        "  print(input_line)\n",
        "\n",
        "  #########\n",
        "\n",
        "    topv, topi = output.topk(n_predictions, 1, True)\n",
        "\n",
        "    for i in range(n_predictions):\n",
        "      value = topv[0][i].item()\n",
        "      category_index = topi[0][i].item()\n",
        "      print('{:.2f} {}'.format(value, all_categories[category_index]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "audXF-a7Dchm"
      },
      "source": [
        "#######"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}