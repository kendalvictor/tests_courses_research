{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import json\n",
    "from collections import Counter\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = Path.cwd()\n",
    "DATA =  BASE / 'data'\n",
    "\n",
    "RAW_SPLITS =  DATA / 'raw_splits_year'\n",
    "PREC_SPLITS =  DATA / 'prec_splits_year'\n",
    "\n",
    "TRAIN = DATA / 'data_train.csv.zip'\n",
    "TEST = DATA / 'data_test.csv.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = DATA / 'train_v2.csv'\n",
    "TEST = DATA / 'test_v2.csv'\n",
    "\n",
    "split_train = pd.read_csv('data_train.csv', encoding='latin-1')\n",
    "split_test = pd.read_csv('data_test.csv', encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256215, 127)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_train['Morosidad'] = np.max(split_train[['SITUACION_DEUDA_BOLETA_2',\n",
    " 'SITUACION_DEUDA_BOLETA_3',\n",
    " 'SITUACION_DEUDA_BOLETA_4',\n",
    " 'SITUACION_DEUDA_BOLETA_5',\n",
    " 'SITUACION_DEUDA_BOLETA_6',\n",
    " 'SITUACION_DEUDA_BOLETA_7',\n",
    " 'SITUACION_DEUDA_BOLETA_8',\n",
    " 'SITUACION_DEUDA_BOLETA_9',\n",
    " 'SITUACION_DEUDA_BOLETA_10']].values, axis=1)\n",
    "split_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256215, 117)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_train = split_train.drop(['SITUACION_DEUDA_BOLETA_1', \n",
    " 'SITUACION_DEUDA_BOLETA_2',\n",
    " 'SITUACION_DEUDA_BOLETA_3',\n",
    " 'SITUACION_DEUDA_BOLETA_4',\n",
    " 'SITUACION_DEUDA_BOLETA_5',\n",
    " 'SITUACION_DEUDA_BOLETA_6',\n",
    " 'SITUACION_DEUDA_BOLETA_7',\n",
    " 'SITUACION_DEUDA_BOLETA_8',\n",
    " 'SITUACION_DEUDA_BOLETA_9',\n",
    " 'SITUACION_DEUDA_BOLETA_10'], axis=1)\n",
    "split_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nan(val):\n",
    "    if (val <=0):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train['EDAD_ANIO_ACTUAL'] = split_train['EDAD_ANIO_ACTUAL'].apply(convert_nan)\n",
    "split_train['EDAD_ANIO_ESTUDIO'] = split_train['EDAD_ANIO_ESTUDIO'].apply(convert_nan)\n",
    "\n",
    "split_test['EDAD_ANIO_ACTUAL'] = split_test['EDAD_ANIO_ACTUAL'].apply(convert_nan)\n",
    "split_test['EDAD_ANIO_ESTUDIO'] = split_test['EDAD_ANIO_ESTUDIO'].apply(convert_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train['TIPO_BECA'] = split_train['TIPO_BECA'].fillna('TIPO_BECA')\n",
    "split_test['TIPO_BECA'] = split_test['TIPO_BECA'].fillna('TIPO_BECA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train['TRABAJA'] = split_train['TRABAJA'].fillna(0)\n",
    "split_test['TRABAJA'] = split_test['TRABAJA'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train['INGRESO_PROPIO'] = split_train['INGRESO_PROPIO'].fillna(0)\n",
    "split_test['INGRESO_PROPIO'] = split_test['INGRESO_PROPIO'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train['NRO_HERMANOS'] = split_train['NRO_HERMANOS'].fillna(0)\n",
    "split_test['NRO_HERMANOS'] = split_test['NRO_HERMANOS'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train['TOT_CURSOS'] = split_train['CURSOSAPROBADOS']+split_train['CURSOSDESAPROBADOS']+split_train['CURSOSNSP']\n",
    "split_test['TOT_CURSOS'] = split_test['CURSOSAPROBADOS']+split_test['CURSOSDESAPROBADOS']+split_test['CURSOSNSP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train['TOT_CRED'] = split_train['CREDAPROBADOS']+split_train['CREDDESAPROBADOS']+split_train['CURSOSNSP']\n",
    "split_test['TOT_CRED'] = split_test['CREDAPROBADOS']+split_test['CREDDESAPROBADOS']+split_test['CURSOSNSP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train['CARRERACONCAT'] = split_train['CARRERA'] + split_train['CARRERA_ACTUAL']\n",
    "split_train['CARRERADISTRITO'] = split_train['CARRERA'] + split_train['CDIST_DESCRIPCION']\n",
    "\n",
    "split_test['CARRERACONCAT'] = split_test['CARRERA'] + split_test['CARRERA_ACTUAL']\n",
    "split_test['CARRERADISTRITO'] = split_test['CARRERA'] + split_test['CDIST_DESCRIPCION']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from category_encoders import *\n",
    "    X_train = split_train.drop(['Morosidad'], axis=1)\n",
    "    y_train = split_train.Morosidad\n",
    "    \n",
    "    # use target encoding to encode two categorical features\n",
    "    enc = TargetEncoder(cols=['CARRERA', 'CARRERA_ACTUAL', 'CARRERADISTRITO', 'CARRERACONCAT']).fit(X_train, y_train)\n",
    "\n",
    "    # transform the datasets\n",
    "    train = enc.transform(X_train)\n",
    "    split_test = enc.transform(split_test)\n",
    "    split_train = pd.concat((train, y_train), axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X_train = split_train.drop(['Morosidad'], axis=1)\n",
    "    y_train = split_train.Morosidad\n",
    "    \n",
    "    # use target encoding to encode two categorical features\n",
    "    enc = TargetEncoder(cols=[\n",
    "       'CDIST_DESCRIPCION']).fit(X_train, y_train)\n",
    "\n",
    "    # transform the datasets\n",
    "    train = enc.transform(X_train)\n",
    "    split_test = enc.transform(split_test)\n",
    "    split_train = pd.concat((train, y_train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## Parsear columnas\n",
    "\n",
    "    split_train['PORC_ASISTENCIA'] = split_train['PORC_ASISTENCIA'].replace('SIN ASISTENCIA TOMADA', np.nan)\n",
    "    split_train['PORC_ASISTENCIA'] = split_train['PORC_ASISTENCIA'].astype(float)\n",
    "\n",
    "    split_train['SITUACION_EGRESO'] = split_train['SITUACION_EGRESO'].replace('NO EGRESO', 0) \n",
    "    split_train['SITUACION_EGRESO'] = split_train['SITUACION_EGRESO'].replace('EGRESO', 1) \n",
    "    split_train['SITUACION_EGRESO'] = split_train['SITUACION_EGRESO'].astype(int)\n",
    "\n",
    "    split_train['SEXO'] = split_train['SEXO'].replace('M', 0) \n",
    "    split_train['SEXO'] = split_train['SEXO'].replace('F', 1) \n",
    "    split_train['SEXO'] = split_train['SEXO'].astype(int)\n",
    "\n",
    "    split_test['PORC_ASISTENCIA'] = split_test['PORC_ASISTENCIA'].replace('SIN ASISTENCIA TOMADA', np.nan)\n",
    "    split_test['PORC_ASISTENCIA'] = split_test['PORC_ASISTENCIA'].astype(float)\n",
    "\n",
    "    split_test['SITUACION_EGRESO'] = split_test['SITUACION_EGRESO'].replace('NO EGRESO', 0) \n",
    "    split_test['SITUACION_EGRESO'] = split_test['SITUACION_EGRESO'].replace('EGRESO', 1) \n",
    "    split_test['SITUACION_EGRESO'] = split_test['SITUACION_EGRESO'].astype(int)\n",
    "\n",
    "    split_test['SEXO'] = split_test['SEXO'].replace('M', 0) \n",
    "    split_test['SEXO'] = split_test['SEXO'].replace('F', 1) \n",
    "    split_test['SEXO'] = split_test['SEXO'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## Remover las columnas\n",
    "\n",
    "    split_train = split_train.drop(['VIVIENDA_DONDE_VIVE','CDEPA_DESCRIPCION', 'CPROV_DESCRIPCION',], axis=1, errors='coerce')\n",
    "    split_test = split_test.drop(['VIVIENDA_DONDE_VIVE','CDEPA_DESCRIPCION', 'CPROV_DESCRIPCION',], axis=1, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## Remover las columnas\n",
    "\n",
    "    split_train = split_train.drop(['TIPO_SEMESTRE'], axis=1)\n",
    "    split_test = split_test.drop(['TIPO_SEMESTRE'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## Aplicando one hot encoding\n",
    "\n",
    "    X_train = split_train.drop(['Morosidad'], axis=1)\n",
    "    y_train = split_train.Morosidad\n",
    "\n",
    "    enc = OneHotEncoder(cols=['TIPO_VIVIENDA_DONDE_VIVE', 'VIVE_CON', 'TIPO_COLEGIO', 'ESTADO_CIVIL']).fit(X_train)\n",
    "\n",
    "    train = enc.transform(X_train)\n",
    "    split_test = enc.transform(split_test)\n",
    "    split_train = pd.concat((train, y_train), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## Sumariazacion de columnas inutiles\n",
    "\n",
    "    filter_col_a = [col for col in split_train.columns if col.startswith('CURSO_MAT_CICLO_')]\n",
    "    split_train['CURSO_MAT_CICLO_SUM'] = split_train[filter_col_a].sum(axis=1)\n",
    "    split_test['CURSO_MAT_CICLO_SUM'] = split_test[filter_col_a].sum(axis=1)\n",
    "\n",
    "    filter_col_b = [col for col in split_train.columns if col.startswith('CRED_MAT_CICLO_')]\n",
    "    split_train['CRED_MAT_CICLO_SUM'] = split_train[filter_col_b].sum(axis=1)\n",
    "    split_test['CRED_MAT_CICLO_SUM'] = split_test[filter_col_b].sum(axis=1)\n",
    "    \n",
    "    split_train['MAT_CICLO_PON'] = 0\n",
    "    split_test['MAT_CICLO_PON'] = 0\n",
    "    for a, b in zip(filter_col_a, filter_col_b):\n",
    "        split_train['MAT_CICLO_PON'] += split_train[a] * split_train[b]\n",
    "        split_test['MAT_CICLO_PON'] += split_test[a] * split_test[b]\n",
    "        \n",
    "    split_train = split_train.drop(filter_col_b, axis=1)\n",
    "    split_test = split_test.drop(filter_col_b, axis=1)\n",
    "    split_train = split_train.drop(filter_col_a, axis=1)\n",
    "    split_test = split_test.drop(filter_col_a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "    filter_col_a = [col for col in split_train.columns if col.startswith('CURSO_MAT_DES_CICLO_')]\n",
    "    split_train['CURSO_MAT_DES_CICLO_SUM'] = split_train[filter_col_a].sum(axis=1)\n",
    "    split_test['CURSO_MAT_DES_CICLO_SUM'] = split_test[filter_col_a].sum(axis=1)\n",
    "\n",
    "    filter_col_b = [col for col in split_train.columns if col.startswith('CRED_MAT_DES_CICLO_')]\n",
    "    split_train['CRED_MAT_DES_CICLO_SUM'] = split_train[filter_col_b].sum(axis=1)\n",
    "    split_test['CRED_MAT_DES_CICLO_SUM'] = split_test[filter_col_b].sum(axis=1)\n",
    "    \n",
    "    split_train['MAT_DES_CICLO_PON'] = 0\n",
    "    split_test['MAT_DES_CICLO_PON'] = 0\n",
    "    for a, b in zip(filter_col_a, filter_col_b):\n",
    "        split_train['MAT_DES_CICLO_PON'] += split_train[a] * split_train[b]\n",
    "        split_test['MAT_DES_CICLO_PON'] += split_test[a] * split_test[b]\n",
    "        \n",
    "    split_train = split_train.drop(filter_col_b, axis=1)\n",
    "    split_test = split_test.drop(filter_col_b, axis=1)\n",
    "    split_train = split_train.drop(filter_col_a, axis=1)\n",
    "    split_test = split_test.drop(filter_col_a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "    split_train['SEM_NOTAS_HIST_INICIA_CARRERA'] = split_train['SEM_NOTAS_HIST_INICIA_CARRERA'].replace('NINGU', np.nan)\n",
    "    split_train['SEM_NOTAS_HIST_INICIA_CARRERA'] = split_train['SEM_NOTAS_HIST_INICIA_CARRERA'].astype(float)\n",
    "    split_test['SEM_NOTAS_HIST_INICIA_CARRERA'] = split_test['SEM_NOTAS_HIST_INICIA_CARRERA'].replace('NINGU', np.nan)\n",
    "    split_test['SEM_NOTAS_HIST_INICIA_CARRERA'] = split_test['SEM_NOTAS_HIST_INICIA_CARRERA'].astype(float)\n",
    "\n",
    "    split_train['SEM_NOTAS_HIST_ULTIMO_CARRERA'] = split_train['SEM_NOTAS_HIST_ULTIMO_CARRERA'].replace('NINGU', np.nan)\n",
    "    split_train['SEM_NOTAS_HIST_ULTIMO_CARRERA'] = split_train['SEM_NOTAS_HIST_ULTIMO_CARRERA'].astype(float)\n",
    "    split_test['SEM_NOTAS_HIST_ULTIMO_CARRERA'] = split_test['SEM_NOTAS_HIST_ULTIMO_CARRERA'].replace('NINGU', np.nan)\n",
    "    split_test['SEM_NOTAS_HIST_ULTIMO_CARRERA'] = split_test['SEM_NOTAS_HIST_ULTIMO_CARRERA'].astype(float)\n",
    "    \n",
    "    split_train['TOT_CIC'] = split_train['SEM_NOTAS_HIST_ULTIMO_CARRERA'] - split_train['SEM_NOTAS_HIST_INICIA_CARRERA'] \n",
    "    split_test['TOT_CIC'] = split_test['SEM_NOTAS_HIST_ULTIMO_CARRERA'] - split_test['SEM_NOTAS_HIST_INICIA_CARRERA']\n",
    "    \n",
    "    split_train.to_csv('train_k_v4.csv', index=False)\n",
    "    split_test.to_csv('test_k_v4.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256215, 87), (44072, 86))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train_k_v4.csv', encoding='latin-1')\n",
    "test = pd.read_csv('test_k_v4.csv', encoding='latin-1')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256215, 85) (256215,)\n",
      "(44072, 85)\n"
     ]
    }
   ],
   "source": [
    "#Preparando el dataset\n",
    "X_train, y_train = train.drop(['COD_ALUMNO', 'Morosidad'], axis=1), train['Morosidad']\n",
    "print(X_train.shape, y_train.shape)\n",
    "X_test = test.drop(['COD_ALUMNO'], axis=1)\n",
    "print(X_test.shape)\n",
    "#Folds\n",
    "skfolds = StratifiedKFold(n_splits=6, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from scipy.stats import mode\n",
    "\n",
    "def print_results(trn_aucs, val_aucs):\n",
    "    train_auc, train_intconf = np.mean(trn_aucs), 2 * np.std(trn_aucs)\n",
    "    val_auc, val_intconf = np.mean(val_aucs), 2 * np.std(val_aucs)\n",
    "    \n",
    "    train_gini, val_gini = (train_auc - 0.5) * 2, (val_auc - 0.5) * 2\n",
    "    train_gini_intconf, val_gini_intconf = train_intconf * 2, val_intconf * 2\n",
    "    \n",
    "    print(f'Train AUC: {100*train_auc:.2f} +/- {100*train_intconf:.2f} | '\n",
    "          f'Val AUC: {100*val_auc:.2f} +/- {100*val_intconf:.2f} | '\n",
    "          f'Train Gini: {100*train_gini:.2f} +/- {100*train_gini_intconf:.2f} | '\n",
    "          f'Val Gini: {100*val_gini:.2f} +/- {100*val_gini_intconf:.2f}')  \n",
    "    return np.mean(trn_aucs), np.mean(val_aucs)\n",
    "\n",
    "def test_lgbm(lgbm, X, y, X_test, kfolds, cat_features, params, num_rounds=1000):\n",
    "    trn_aucs, val_aucs, trn_f1, val_f1 = [], [], [], []\n",
    "    y_pred = np.zeros(len(X))\n",
    "    y_test = np.zeros(len(X_test))\n",
    "    models = []\n",
    "    evals_result = []\n",
    "    for trn_idx, val_idx in kfolds.split(X, y):\n",
    "        eval_result = {}\n",
    "        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "        X_trn, y_trn = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "        dtrn = lgbm.Dataset(X_trn, y_trn)\n",
    "        dval = lgbm.Dataset(X_val, y_val)\n",
    "        bst = lgbm.train(params, dtrn, num_rounds, [dval],\n",
    "                  early_stopping_rounds=30, categorical_feature=cat_features, feval=lgb_f1_score, \n",
    "                         evals_result=eval_result,\n",
    "                  verbose_eval=False)\n",
    "        evals_result.append(eval_result)\n",
    "        y_trn_pred = bst.predict(X_trn)\n",
    "        y_val_pred = bst.predict(X_val)\n",
    "        trn_aucs.append(roc_auc_score(y_trn, y_trn_pred))\n",
    "        val_aucs.append(roc_auc_score(y_val, y_val_pred))\n",
    "        \n",
    "        print(f'No. estimators: {bst.best_iteration} | '\n",
    "              f'Train AUC: {100*trn_aucs[-1]:.2f} | '\n",
    "              f'Val AUC: {100*val_aucs[-1]:.2f} | '\n",
    "              f'Train Gini: {(100*trn_aucs[-1]-50)*2:.2f} | '\n",
    "              f'Val Gini: {(100*val_aucs[-1]-50)*2:.2f} | ')\n",
    "        \n",
    "        y_tst_pred = bst.predict(X_test)\n",
    "        y_test += y_tst_pred\n",
    "        y_pred[val_idx] = y_val_pred\n",
    "        \n",
    "        models.append(bst)\n",
    "        \n",
    "    print()\n",
    "    print_results(trn_aucs, val_aucs)\n",
    "    print()\n",
    "    return y_test / kfolds.n_splits, y_pred, models, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SIN BECA                                154995\n",
       "CONVENIO POLICIA NACIONAL                37308\n",
       "DSCTO. PADRES CON VARIOS HIJOS           16246\n",
       "BECA RENDIMIENTO Y STCION. ECONOMICA     12194\n",
       "CONVENIO EJERCITO PERUANO                 9228\n",
       "CONVENIO FUERZA AEREA DEL PERU            7529\n",
       "DSCTO. HIJOS DE GRADUADOS DE URP          7239\n",
       "CONVENIO MARINA DE GUERRA DEL PERU        5475\n",
       "HIJO DE TRABAJADOR ADMINISTRATIVO         2487\n",
       "DEPORTITAS CALIFICADOS                    1039\n",
       "HIJO DE DOCENTE TIEMPO PARCIAL             955\n",
       "BECA ORFANDAD                              876\n",
       "HIJO DE DOCENTE TIEMPO COMPLETO            384\n",
       "BECA PRIMEROS PUESTOS REGULAR              129\n",
       "TRABAJADOR ADMINISTRATIVO                  110\n",
       "CONVENIO HOSP.DA.CARRION                     7\n",
       "TIPO_BECA                                    7\n",
       "BECA_HIJO TRAB_JUBILADO                      7\n",
       "Name: TIPO_BECA, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['TIPO_BECA'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool. Did not expect the data types in fields TIPO_BECA",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-10be656b6b01>\u001b[0m in \u001b[0;36mtest_lgbm\u001b[0;34m(lgbm, X, y, X_test, kfolds, cat_features, params, num_rounds)\u001b[0m\n\u001b[1;32m     33\u001b[0m                   \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlgb_f1_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                          \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                   verbose_eval=False)\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mevals_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0my_trn_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[1;32m   1451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0;32m-> 1453\u001b[0;31m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1454\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    957\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m                                 \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[1;32m    960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0mcategorical_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_data_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_label_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_has_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\"DataFrame.dtypes for data must be int, float or bool. Did not expect the data types in fields \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool. Did not expect the data types in fields TIPO_BECA"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#### SUBMISSION ####\n",
    "params = {'bagging_fraction': '0.9761679761799377',\n",
    "  'feature_fraction': '0.7816500852961176',\n",
    "  'lambda_l1': '0.13407390174373368',\n",
    "  'lambda_l2': '2.212572925712077',\n",
    "  'max_depth': '8',\n",
    "  'min_child_weight': '5.232240193423142',\n",
    "  'min_split_gain': '0.09208559917489269',\n",
    "  'num_leaves': '44',\n",
    " 'objective':'binary', 'metric': 'None', 'gpu_device_id': '1'}\n",
    "y_test, y_pred, models, evals = test_lgbm(lightgbm, X_train, y_train, X_test, skfolds, [], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-14a62777cac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mthold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_test_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test_f1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "thold = 0.5\n",
    "y_test_f1 = []\n",
    "for val in y_test:\n",
    "    if(val < thold): y_test_f1.append(0)\n",
    "    else:\n",
    "        y_test_f1.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame()\n",
    "sub_df['COD_ALUMNO'] = test['COD_ALUMNO']\n",
    "sub_df['Morosidad'] = y_test_f1\n",
    "sub_df.to_csv('sub_k17.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
