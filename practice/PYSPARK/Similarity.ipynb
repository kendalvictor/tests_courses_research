{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark \n",
    "findspark.init()\n",
    "\n",
    "from pyspark.ml.feature import MinHashLSH, BucketedRandomProjectionLSH\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import coalesce, udf, struct, col, lit, unix_timestamp, count, when, isnan, isnull, split\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from IPython.display import display\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, MinMaxScaler\n",
    "from pyspark.ml.clustering import KMeans, GaussianMixture, BisectingKMeans\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "spark = SparkSession.builder.appName('laptop_everis').getOrCreate()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1ER METODO USANDO KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262144 256\n",
      "236195 256 25949 256\n"
     ]
    }
   ],
   "source": [
    "SEED = 29082013\n",
    "\n",
    "df = spark.read.csv(\"train.csv\", header=True, nullValue=\"?\", inferSchema=True)\n",
    "train, test = df.randomSplit([0.9, 0.1], seed=SEED)\n",
    "#ds.printSchema()\n",
    "\n",
    "# SELECT COLUMNS\n",
    "cols_features = df.columns[1:-1]\n",
    "print(df.count(), len(cols_features))\n",
    "del df\n",
    "print(train.count(), len(train.columns[1:-1]), test.count(), len(test.columns[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_scaler_df(cols_features, ds, scaled=True):\n",
    "    \"\"\"\n",
    "        Vectorized and Scaled features \n",
    "    \"\"\"\n",
    "    assembler = VectorAssembler(inputCols=cols_features, outputCol=\"features\")\n",
    "    scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "    \n",
    "    stages = [assembler]\n",
    "    if scaled:\n",
    "        stages.append(scaler)\n",
    "    \n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    _proccess = pipeline.fit(ds)\n",
    "    \n",
    "    ds = _proccess.transform(ds).drop(*cols_features)\n",
    "    if scaled:\n",
    "        ds = ds.drop(\"features\")\n",
    "        \n",
    "    display(ds.show(5))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+\n",
      "|                  id|target|            features|\n",
      "+--------------------+------+--------------------+\n",
      "|00006042e379fc155...|     0|[-0.043731,-0.009...|\n",
      "|00034f0082232ad8f...|     1|[2.749005,0.24356...|\n",
      "|00036a71992c149e9...|     1|[2.317103,-4.3215...|\n",
      "|0007233584b5a85b4...|     1|[-9.570656,-5.163...|\n",
      "|000863c7e31c5f2c6...|     1|[1.436977,0.63941...|\n",
      "+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+\n",
      "|                  id|target|            features|\n",
      "+--------------------+------+--------------------+\n",
      "|0008851be01140e75...|     0|[1.633524,5.21490...|\n",
      "|00161f97cdda20b20...|     0|[0.810057,0.28687...|\n",
      "|002973cbedd83d830...|     1|[0.07062,5.837957...|\n",
      "|002bde7fd91b49aaa...|     0|[1.146199,-0.0767...|\n",
      "|003cb39fb6c0a2556...|     1|[1.542351,0.08234...|\n",
      "+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = vector_scaler_df(\n",
    "    cols_features, train, scaled=False\n",
    ")\n",
    "test = vector_scaler_df(\n",
    "    cols_features, test, scaled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__del__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__metaclass__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_call_java', '_clear', '_copyValues', '_copy_params', '_create_from_java_class', '_create_params_from_java', '_defaultParamMap', '_dummy', '_empty_java_param_map', '_from_java', '_java_obj', '_make_java_param_pair', '_new_java_array', '_new_java_obj', '_paramMap', '_params', '_randomUID', '_resetUid', '_resolveParam', '_set', '_setDefault', '_shouldOwn', '_to_java', '_transfer_param_map_from_java', '_transfer_param_map_to_java', '_transfer_params_from_java', '_transfer_params_to_java', '_transform', 'clusterCenters', 'computeCost', 'copy', 'distanceMeasure', 'explainParam', 'explainParams', 'extractParamMap', 'featuresCol', 'getOrDefault', 'getParam', 'hasDefault', 'hasParam', 'hasSummary', 'isDefined', 'isSet', 'k', 'load', 'maxIter', 'minDivisibleClusterSize', 'params', 'predictionCol', 'read', 'save', 'seed', 'set', 'summary', 'transform', 'uid', 'write']\n"
     ]
    }
   ],
   "source": [
    "# DECLARE PARAMETERS\n",
    "clusters = 3\n",
    "max_iter = 100\n",
    "\n",
    "# TRAIN AND PREDICT\n",
    "kmeans_clf = BisectingKMeans()\\\n",
    "         .setK(clusters)\\\n",
    "         .setMaxIter(max_iter)\\\n",
    "         .setSeed(SEED)\\\n",
    "         .setFeaturesCol(\"features\")\\\n",
    "         .setPredictionCol(\"cluster\")\\\n",
    "         .setDistanceMeasure(\"euclidean\")\n",
    "\n",
    "model_km = kmeans_clf.fit(train)\n",
    "print(dir(model_km))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__del__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__metaclass__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_call_java', '_clear', '_copyValues', '_copy_params', '_create_from_java_class', '_create_model', '_create_params_from_java', '_defaultParamMap', '_dummy', '_empty_java_param_map', '_fit', '_fit_java', '_from_java', '_input_kwargs', '_java_obj', '_make_java_param_pair', '_new_java_array', '_new_java_obj', '_paramMap', '_params', '_randomUID', '_resetUid', '_resolveParam', '_set', '_setDefault', '_shouldOwn', '_to_java', '_transfer_param_map_from_java', '_transfer_param_map_to_java', '_transfer_params_from_java', '_transfer_params_to_java', 'copy', 'distanceMeasure', 'explainParam', 'explainParams', 'extractParamMap', 'featuresCol', 'fit', 'fitMultiple', 'getDistanceMeasure', 'getFeaturesCol', 'getK', 'getMaxIter', 'getMinDivisibleClusterSize', 'getOrDefault', 'getParam', 'getPredictionCol', 'getSeed', 'hasDefault', 'hasParam', 'isDefined', 'isSet', 'k', 'load', 'maxIter', 'minDivisibleClusterSize', 'params', 'predictionCol', 'read', 'save', 'seed', 'set', 'setDistanceMeasure', 'setFeaturesCol', 'setK', 'setMaxIter', 'setMinDivisibleClusterSize', 'setParams', 'setPredictionCol', 'setSeed', 'uid', 'write']\n"
     ]
    }
   ],
   "source": [
    "print(dir(kmeans_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+-------+\n",
      "|                  id|target|            features|cluster|\n",
      "+--------------------+------+--------------------+-------+\n",
      "|00006042e379fc155...|     0|[-0.043731,-0.009...|      2|\n",
      "|00034f0082232ad8f...|     1|[2.749005,0.24356...|      0|\n",
      "|00036a71992c149e9...|     1|[2.317103,-4.3215...|      1|\n",
      "|0007233584b5a85b4...|     1|[-9.570656,-5.163...|      0|\n",
      "|000863c7e31c5f2c6...|     1|[1.436977,0.63941...|      0|\n",
      "|0008dfd4b7ed96f06...|     1|[-0.682157,0.8953...|      1|\n",
      "|000911571fb8a1f13...|     1|[0.214299,-1.0811...|      0|\n",
      "|000ae59f3d37d7798...|     0|[-0.399398,1.8554...|      0|\n",
      "|000d87dbb6b79672c...|     0|[0.753058,0.87277...|      0|\n",
      "|000f46bfffa3951a8...|     1|[-1.352792,-0.081...|      0|\n",
      "|00119677d32d59472...|     1|[-1.680918,-0.032...|      1|\n",
      "|0012110e04af66071...|     1|[-0.517875,-1.848...|      1|\n",
      "|001243c85b77b2bda...|     1|[1.415826,-2.3050...|      1|\n",
      "|00130de7cf79838a0...|     1|[2.343037,0.71798...|      2|\n",
      "|0013c5d08f59e6310...|     0|[0.134893,-1.2554...|      0|\n",
      "|00156f595cd45c8b5...|     0|[0.233349,-0.5461...|      1|\n",
      "|00163d20a5e50c2c5...|     0|[-0.684427,0.2366...|      0|\n",
      "|00188c43276013078...|     1|[-0.252563,-1.770...|      0|\n",
      "|0018da43205bb7b22...|     0|[-1.153068,2.3349...|      0|\n",
      "|0018f4b3976ac811c...|     0|[-1.073428,-0.441...|      0|\n",
      "+--------------------+------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_km.transform(train).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+-------+\n",
      "|                  id|target|            features|cluster|\n",
      "+--------------------+------+--------------------+-------+\n",
      "|0008851be01140e75...|     0|[1.633524,5.21490...|      2|\n",
      "|00161f97cdda20b20...|     0|[0.810057,0.28687...|      0|\n",
      "|002973cbedd83d830...|     1|[0.07062,5.837957...|      2|\n",
      "|002bde7fd91b49aaa...|     0|[1.146199,-0.0767...|      0|\n",
      "|003cb39fb6c0a2556...|     1|[1.542351,0.08234...|      0|\n",
      "|0045ccf444c75d050...|     0|[0.421806,-0.2879...|      2|\n",
      "|00637dfbac621f4e5...|     0|[-0.70026,0.74640...|      2|\n",
      "|0066c2b57dfa271f4...|     0|[0.682159,0.43132...|      0|\n",
      "|007856881856ea586...|     1|[0.029747,-0.3572...|      2|\n",
      "|007d8978c0a14237b...|     0|[-1.499893,-1.557...|      0|\n",
      "|0082a40276f7d89e9...|     0|[-1.442629,2.0681...|      0|\n",
      "|0084c2f5fe4eb1d21...|     1|[1.760883,1.51477...|      0|\n",
      "|009c0d9555ea91b54...|     0|[-4.279094,0.7883...|      0|\n",
      "|00a017990137d4d4c...|     0|[-1.190355,-0.630...|      1|\n",
      "|00a166b06d78fcbde...|     0|[-0.917051,-1.029...|      0|\n",
      "|00a59ab2d023a2efe...|     0|[2.181096,1.28525...|      0|\n",
      "|00bec45f070c42a99...|     0|[-1.916388,-0.637...|      2|\n",
      "|00cf59d9005b8c73f...|     1|[2.113761,-0.5044...|      2|\n",
      "|00d0dd938f30f5f10...|     1|[-1.520099,-0.497...|      1|\n",
      "|00d72de0194e8b869...|     0|[3.336594,-0.8847...|      0|\n",
      "+--------------------+------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_with_cluster = model_km.transform(test)\n",
    "test_with_cluster.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for center in model_km.clusterCenters():\n",
    "    print(type(center))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Cluster Centers: \n",
      "<class 'list'> 256 [0.004476, -0.00708, -0.003175, -0.009977, 0.00495, 0.004227, 0.015417, -0.002271, 0.012098, 0.012234]\n",
      "<class 'list'> 256 [0.015768, 0.010681, -0.031701, -0.005772, 0.005109, 0.011642, -0.004091, -0.021232, -0.007003, 0.022971]\n",
      "<class 'list'> 256 [-0.005795, 0.011798, -0.011847, -0.00244, -0.001008, 0.015484, -0.042012, 0.000765, -0.008965, 0.030481]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los centroides.\n",
    "import numpy as np\n",
    "\n",
    "centers = [list([float(num) for num in _]) for _ in np.round(model_km.clusterCenters(), 6)]\n",
    "print(type(centers))\n",
    "\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(type(center), len(center), center[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom scipy.spatial.distance import jaccard, cosine, euclidean\\nimport pyspark.sql.functions as F\\nfrom pyspark.sql.types import FloatType\\nfrom scipy.spatial import distance\\n\\norder = 0\\n\\nfor center in centers:\\n    distance_udf = F.udf(lambda x: float(euclidean(x, center)), FloatType())\\n    cluster_train = cluster_train.withColumn('distance_centroid_{}'.format(order), distance_udf(F.col('scaled_features')))\\n    order += 1\\n\\ncluster_train.show(15)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from scipy.spatial.distance import jaccard, cosine, euclidean\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import FloatType\n",
    "from scipy.spatial import distance\n",
    "\n",
    "order = 0\n",
    "\n",
    "for center in centers:\n",
    "    distance_udf = F.udf(lambda x: float(euclidean(x, center)), FloatType())\n",
    "    cluster_train = cluster_train.withColumn('distance_centroid_{}'.format(order), distance_udf(F.col('scaled_features')))\n",
    "    order += 1\n",
    "\n",
    "cluster_train.show(15)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\norder = 0\\n\\nfor center in centers:\\n    distance_udf = F.udf(lambda x: float(euclidean(x, center)), FloatType())\\n    cluster_test = cluster_test.withColumn('distance_centroid_{}'.format(order), distance_udf(F.col('scaled_features')))\\n    order += 1\\n\\ncluster_test.show(15)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "order = 0\n",
    "\n",
    "for center in centers:\n",
    "    distance_udf = F.udf(lambda x: float(euclidean(x, center)), FloatType())\n",
    "    cluster_test = cluster_test.withColumn('distance_centroid_{}'.format(order), distance_udf(F.col('scaled_features')))\n",
    "    order += 1\n",
    "\n",
    "cluster_test.show(15)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[0.004476,-0.0070...|\n",
      "|[0.015768,0.01068...|\n",
      "|[-0.005795,0.0117...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[0.004476,-0.0070...|\n",
      "|[0.015768,0.01068...|\n",
      "|[-0.005795,0.0117...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, FloatType, DoubleType\n",
    "\n",
    "df_centers = sc.parallelize(centers).toDF(cols_features)\n",
    "df_centers = vector_scaler_df(cols_features, df_centers, scaled=False)\n",
    "print(type(df_centers))\n",
    "df_centers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'target', 'features']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                  id|            features|\n",
      "+--------------------+--------------------+\n",
      "|00006042e379fc155...|[-0.043731,-0.009...|\n",
      "|00034f0082232ad8f...|[2.749005,0.24356...|\n",
      "|00036a71992c149e9...|[2.317103,-4.3215...|\n",
      "|0007233584b5a85b4...|[-9.570656,-5.163...|\n",
      "|000863c7e31c5f2c6...|[1.436977,0.63941...|\n",
      "|0008dfd4b7ed96f06...|[-0.682157,0.8953...|\n",
      "|000911571fb8a1f13...|[0.214299,-1.0811...|\n",
      "|000ae59f3d37d7798...|[-0.399398,1.8554...|\n",
      "|000d87dbb6b79672c...|[0.753058,0.87277...|\n",
      "|000f46bfffa3951a8...|[-1.352792,-0.081...|\n",
      "|00119677d32d59472...|[-1.680918,-0.032...|\n",
      "|0012110e04af66071...|[-0.517875,-1.848...|\n",
      "|001243c85b77b2bda...|[1.415826,-2.3050...|\n",
      "|00130de7cf79838a0...|[2.343037,0.71798...|\n",
      "|0013c5d08f59e6310...|[0.134893,-1.2554...|\n",
      "|00156f595cd45c8b5...|[0.233349,-0.5461...|\n",
      "|00163d20a5e50c2c5...|[-0.684427,0.2366...|\n",
      "|00188c43276013078...|[-0.252563,-1.770...|\n",
      "|0018da43205bb7b22...|[-1.153068,2.3349...|\n",
      "|0018f4b3976ac811c...|[-1.073428,-0.441...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "only_features = train.select('id', 'features')\n",
    "only_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor row in only_features.take(5):\\n    print(\"----- ------------------\", type(row))\\n    for vect in row:\\n        print(\"///// \", type(vect))\\n        for val in vect:\\n            print(type(val))\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for row in only_features.take(5):\n",
    "    print(\"----- ------------------\", type(row))\n",
    "    for vect in row:\n",
    "        print(\"///// \", type(vect))\n",
    "        for val in vect:\n",
    "            print(type(val))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom pyspark.sql import types\\nonly_features = only_features.withColumn(\\n    \"features_x\", only_features[\"features\"].cast(\\n        types.ArrayType(\\n            types.DoubleType()\\n        )\\n    )\\n)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from pyspark.sql import types\n",
    "only_features = only_features.withColumn(\n",
    "    \"features_x\", only_features[\"features\"].cast(\n",
    "        types.ArrayType(\n",
    "            types.DoubleType()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(id,StringType,true),StructField(features,VectorUDT,true)))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_features.schema\n",
    "#StructType(List(StructField(features,VectorUDT,true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236195"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_features.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(BucketedRandomProjectionLSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__del__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__metaclass__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_call_java', '_clear', '_copyValues', '_copy_params', '_create_from_java_class', '_create_params_from_java', '_defaultParamMap', '_dummy', '_empty_java_param_map', '_from_java', '_java_obj', '_make_java_param_pair', '_new_java_array', '_new_java_obj', '_paramMap', '_params', '_randomUID', '_resetUid', '_resolveParam', '_set', '_setDefault', '_shouldOwn', '_to_java', '_transfer_param_map_from_java', '_transfer_param_map_to_java', '_transfer_params_from_java', '_transfer_params_to_java', '_transform', 'approxNearestNeighbors', 'approxSimilarityJoin', 'bucketLength', 'copy', 'explainParam', 'explainParams', 'extractParamMap', 'getOrDefault', 'getParam', 'hasDefault', 'hasParam', 'inputCol', 'isDefined', 'isSet', 'load', 'numHashTables', 'outputCol', 'params', 'read', 'save', 'set', 'transform', 'uid', 'write']\n"
     ]
    }
   ],
   "source": [
    "brp2 = BucketedRandomProjectionLSH(\n",
    "    inputCol=\"features\", outputCol=\"hashes\", bucketLength=1\n",
    ")\n",
    "model_lsh = brp2.fit(df_centers)\n",
    "print(dir(model_lsh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_lsh.transform(only_features).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method approxNearestNeighbors in module pyspark.ml.feature:\n",
      "\n",
      "approxNearestNeighbors(dataset, key, numNearestNeighbors, distCol='distCol') method of pyspark.ml.feature.BucketedRandomProjectionLSHModel instance\n",
      "    Given a large dataset and an item, approximately find at most k items which have the\n",
      "    closest distance to the item. If the :py:attr:`outputCol` is missing, the method will\n",
      "    transform the data; if the :py:attr:`outputCol` exists, it will use that. This allows\n",
      "    caching of the transformed data when necessary.\n",
      "    \n",
      "    .. note:: This method is experimental and will likely change behavior in the next release.\n",
      "    \n",
      "    :param dataset: The dataset to search for nearest neighbors of the key.\n",
      "    :param key: Feature vector representing the item to search for.\n",
      "    :param numNearestNeighbors: The maximum number of nearest neighbors.\n",
      "    :param distCol: Output column for storing the distance between each result row and the key.\n",
      "                    Use \"distCol\" as default value if it's not specified.\n",
      "    :return: A dataset containing at most k items closest to the key. A column \"distCol\" is\n",
      "             added to show the distance between each row and the key.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model_lsh.approxNearestNeighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> 256 [ 0.00447589 -0.00707993 -0.0031752  -0.00997688  0.00494996  0.0042267\n",
      "  0.01541673 -0.00227112  0.01209811  0.01223353]\n",
      "<class 'numpy.ndarray'> 256 [ 0.01576845  0.01068113 -0.03170115 -0.0057719   0.00510861  0.01164214\n",
      " -0.00409054 -0.02123242 -0.00700264  0.02297098]\n",
      "<class 'numpy.ndarray'> 256 [-0.00579469  0.0117981  -0.0118467  -0.00244003 -0.00100815  0.01548432\n",
      " -0.04201236  0.0007651  -0.00896459  0.03048135]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "order = 0\n",
    "\n",
    "for center in model_km.clusterCenters():\n",
    "    \n",
    "    print(type(center), center.size, center[:10])\n",
    "    _result = model_lsh.approxNearestNeighbors(\n",
    "        only_features, Vectors.dense(center), 1\n",
    "    )\n",
    "    _result = _result.withColumn(\"cluster\", lit(order))\n",
    "    df_result = _result if order <= 0 else df_result.union(_result)\n",
    "    \n",
    "    order += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|cluster|     id_representant|\n",
      "+-------+--------------------+\n",
      "|      0|0eb9a64ef4ace1d18...|\n",
      "|      1|00a4aae9bb201b156...|\n",
      "|      2|b795fad07ee300251...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result = df_result.select('cluster', col(\"id\").alias(\"id_representant\"))\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+-------+-------+--------------------+\n",
      "|                  id|target|            features|cluster|cluster|     id_representant|\n",
      "+--------------------+------+--------------------+-------+-------+--------------------+\n",
      "|0008851be01140e75...|     0|[1.633524,5.21490...|      2|      2|b795fad07ee300251...|\n",
      "|00161f97cdda20b20...|     0|[0.810057,0.28687...|      0|      0|0eb9a64ef4ace1d18...|\n",
      "|002973cbedd83d830...|     1|[0.07062,5.837957...|      2|      2|b795fad07ee300251...|\n",
      "|002bde7fd91b49aaa...|     0|[1.146199,-0.0767...|      0|      0|0eb9a64ef4ace1d18...|\n",
      "|003cb39fb6c0a2556...|     1|[1.542351,0.08234...|      0|      0|0eb9a64ef4ace1d18...|\n",
      "|0045ccf444c75d050...|     0|[0.421806,-0.2879...|      2|      2|b795fad07ee300251...|\n",
      "|00637dfbac621f4e5...|     0|[-0.70026,0.74640...|      2|      2|b795fad07ee300251...|\n",
      "|0066c2b57dfa271f4...|     0|[0.682159,0.43132...|      0|      0|0eb9a64ef4ace1d18...|\n",
      "|007856881856ea586...|     1|[0.029747,-0.3572...|      2|      2|b795fad07ee300251...|\n",
      "|007d8978c0a14237b...|     0|[-1.499893,-1.557...|      0|      0|0eb9a64ef4ace1d18...|\n",
      "|0082a40276f7d89e9...|     0|[-1.442629,2.0681...|      0|      0|0eb9a64ef4ace1d18...|\n",
      "|0084c2f5fe4eb1d21...|     1|[1.760883,1.51477...|      0|      0|0eb9a64ef4ace1d18...|\n",
      "|009c0d9555ea91b54...|     0|[-4.279094,0.7883...|      0|      0|0eb9a64ef4ace1d18...|\n",
      "|00a017990137d4d4c...|     0|[-1.190355,-0.630...|      1|      1|00a4aae9bb201b156...|\n",
      "|00a166b06d78fcbde...|     0|[-0.917051,-1.029...|      0|      0|0eb9a64ef4ace1d18...|\n",
      "|00a59ab2d023a2efe...|     0|[2.181096,1.28525...|      0|      0|0eb9a64ef4ace1d18...|\n",
      "|00bec45f070c42a99...|     0|[-1.916388,-0.637...|      2|      2|b795fad07ee300251...|\n",
      "|00cf59d9005b8c73f...|     1|[2.113761,-0.5044...|      2|      2|b795fad07ee300251...|\n",
      "|00d0dd938f30f5f10...|     1|[-1.520099,-0.497...|      1|      1|00a4aae9bb201b156...|\n",
      "|00d72de0194e8b869...|     0|[3.336594,-0.8847...|      0|      0|0eb9a64ef4ace1d18...|\n",
      "+--------------------+------+--------------------+-------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_with_cluster = test_with_cluster.join(\n",
    "    df_result, test_with_cluster.cluster == df_result.cluster, how='left'\n",
    ")\n",
    "test_with_cluster.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25949"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_with_cluster.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
