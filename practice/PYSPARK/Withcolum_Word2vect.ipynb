{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANALISIS DE WITH COLUM SIMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+------+------+-----------+\n",
       "fruit1|fruit2|waaaaaaaaaa|\n",
       "+------+------+-----------+\n",
       "orange| apple|      apple|\n",
       "  kiwi|  null|       null|\n",
       "  null|banana|     banana|\n",
       " mango| mango|      mango|\n",
       "  null|  null|       null|\n",
       "+------+------+-----------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = sc.parallelize([\n",
    "    (\"orange\", \"apple\"), (\"kiwi\", None), (None, \"banana\"), \n",
    "    (\"mango\", \"mango\"), (None, None)\n",
    "]).toDF([\"fruit1\", \"fruit2\"])\n",
    "\n",
    "df.withColumn('waaaaaaaaaa', df.fruit2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRUBEAS PARAMETROS WORD2VECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# UDF PARA OTENER TAMANNO DE ELEMENTOS LISTA\n",
    "@udf(\"int\")\n",
    "def len_list(_list):\n",
    "  return len(_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------------------+------------+\n",
       "            sentence|len_sentence|\n",
       "+--------------------+------------+\n",
       "[a, b, a, b, a, b...|         221|\n",
       "[a, b, a, b, a, b...|         221|\n",
       "[a, b, a, b, a, b...|         221|\n",
       "[e, f, e, f, e, f...|         221|\n",
       "[e, f, e, f, e, f...|         221|\n",
       "[e, f, e, f, e, f...|         221|\n",
       "+--------------------+------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent = (\"a b \" * 100 + \"a c \" * 10).split(\" \")\n",
    "sent2 = (\"a b \" * 99 + \"a c \" * 11).split(\" \")\n",
    "sent3 = (\"a b \" * 101 + \"a c \" * 9).split(\" \")\n",
    "\n",
    "sent4 = (\"e f \" * 100 + \"a k \" * 10).split(\" \")\n",
    "sent5 = (\"e f \" * 99 + \"a k \" * 11).split(\" \")\n",
    "sent6 = (\"e f \" * 101 + \"a k \" * 9).split(\" \")\n",
    "\n",
    "doc = spark.createDataFrame(\n",
    "  [(sent,), (sent2,), (sent3,), (sent4,), (sent5,), (sent6,)], \n",
    "  [\"sentence\"]\n",
    ")\n",
    "doc = doc.withColumn(\"len_sentence\", len_list(doc['sentence']))\n",
    "doc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Help on class Word2Vec in module pyspark.ml.feature:\n",
       "\n",
       "class Word2Vec(pyspark.ml.wrapper.JavaEstimator, pyspark.ml.param.shared.HasStepSize, pyspark.ml.param.shared.HasMaxIter, pyspark.ml.param.shared.HasSeed, pyspark.ml.param.shared.HasInputCol, pyspark.ml.param.shared.HasOutputCol, pyspark.ml.util.JavaMLReadable, pyspark.ml.util.JavaMLWritable)\n",
       "  Word2Vec trains a model of &#96;Map(String, Vector)&#96;, i.e. transforms a word into a code for further\n",
       "  natural language processing or machine learning process.\n",
       "  \n",
       "  &gt;&gt;&gt; sent = (&quot;a b &quot; * 100 + &quot;a c &quot; * 10).split(&quot; &quot;)\n",
       "  &gt;&gt;&gt; doc = spark.createDataFrame([(sent,), (sent,)], [&quot;sentence&quot;])\n",
       "  &gt;&gt;&gt; word2Vec = Word2Vec(vectorSize=5, seed=42, inputCol=&quot;sentence&quot;, outputCol=&quot;model&quot;)\n",
       "  &gt;&gt;&gt; model = word2Vec.fit(doc)\n",
       "  &gt;&gt;&gt; model.getVectors().show()\n",
       "  +----+--------------------+\n",
       "  |word|              vector|\n",
       "  +----+--------------------+\n",
       "  |   a|[0.09461779892444...|\n",
       "  |   b|[1.15474212169647...|\n",
       "  |   c|[-0.3794820010662...|\n",
       "  +----+--------------------+\n",
       "  ...\n",
       "  &gt;&gt;&gt; model.findSynonymsArray(&quot;a&quot;, 2)\n",
       "  [(&apos;b&apos;, 0.25053444504737854), (&apos;c&apos;, -0.6980510950088501)]\n",
       "  &gt;&gt;&gt; from pyspark.sql.functions import format_number as fmt\n",
       "  &gt;&gt;&gt; model.findSynonyms(&quot;a&quot;, 2).select(&quot;word&quot;, fmt(&quot;similarity&quot;, 5).alias(&quot;similarity&quot;)).show()\n",
       "  +----+----------+\n",
       "  |word|similarity|\n",
       "  +----+----------+\n",
       "  |   b|   0.25053|\n",
       "  |   c|  -0.69805|\n",
       "  +----+----------+\n",
       "  ...\n",
       "  &gt;&gt;&gt; model.transform(doc).head().model\n",
       "  DenseVector([0.5524, -0.4995, -0.3599, 0.0241, 0.3461])\n",
       "  &gt;&gt;&gt; word2vecPath = temp_path + &quot;/word2vec&quot;\n",
       "  &gt;&gt;&gt; word2Vec.save(word2vecPath)\n",
       "  &gt;&gt;&gt; loadedWord2Vec = Word2Vec.load(word2vecPath)\n",
       "  &gt;&gt;&gt; loadedWord2Vec.getVectorSize() == word2Vec.getVectorSize()\n",
       "  True\n",
       "  &gt;&gt;&gt; loadedWord2Vec.getNumPartitions() == word2Vec.getNumPartitions()\n",
       "  True\n",
       "  &gt;&gt;&gt; loadedWord2Vec.getMinCount() == word2Vec.getMinCount()\n",
       "  True\n",
       "  &gt;&gt;&gt; modelPath = temp_path + &quot;/word2vec-model&quot;\n",
       "  &gt;&gt;&gt; model.save(modelPath)\n",
       "  &gt;&gt;&gt; loadedModel = Word2VecModel.load(modelPath)\n",
       "  &gt;&gt;&gt; loadedModel.getVectors().first().word == model.getVectors().first().word\n",
       "  True\n",
       "  &gt;&gt;&gt; loadedModel.getVectors().first().vector == model.getVectors().first().vector\n",
       "  True\n",
       "  \n",
       "  .. versionadded:: 1.4.0\n",
       "  \n",
       "  Method resolution order:\n",
       "      Word2Vec\n",
       "      pyspark.ml.wrapper.JavaEstimator\n",
       "      pyspark.ml.wrapper.JavaParams\n",
       "      pyspark.ml.wrapper.JavaWrapper\n",
       "      pyspark.ml.base.Estimator\n",
       "      pyspark.ml.param.shared.HasStepSize\n",
       "      pyspark.ml.param.shared.HasMaxIter\n",
       "      pyspark.ml.param.shared.HasSeed\n",
       "      pyspark.ml.param.shared.HasInputCol\n",
       "      pyspark.ml.param.shared.HasOutputCol\n",
       "      pyspark.ml.param.Params\n",
       "      pyspark.ml.util.Identifiable\n",
       "      pyspark.ml.util.JavaMLReadable\n",
       "      pyspark.ml.util.MLReadable\n",
       "      pyspark.ml.util.JavaMLWritable\n",
       "      pyspark.ml.util.MLWritable\n",
       "      builtins.object\n",
       "  \n",
       "  Methods defined here:\n",
       "  \n",
       "  __init__(self, vectorSize=100, minCount=5, numPartitions=1, stepSize=0.025, maxIter=1, seed=None, inputCol=None, outputCol=None, windowSize=5, maxSentenceLength=1000)\n",
       "      __init__(self, vectorSize=100, minCount=5, numPartitions=1, stepSize=0.025, maxIter=1,                  seed=None, inputCol=None, outputCol=None, windowSize=5, maxSentenceLength=1000)\n",
       "  \n",
       "  getMaxSentenceLength(self)\n",
       "      Gets the value of maxSentenceLength or its default value.\n",
       "      \n",
       "      .. versionadded:: 2.0.0\n",
       "  \n",
       "  getMinCount(self)\n",
       "      Gets the value of minCount or its default value.\n",
       "      \n",
       "      .. versionadded:: 1.4.0\n",
       "  \n",
       "  getNumPartitions(self)\n",
       "      Gets the value of numPartitions or its default value.\n",
       "      \n",
       "      .. versionadded:: 1.4.0\n",
       "  \n",
       "  getVectorSize(self)\n",
       "      Gets the value of vectorSize or its default value.\n",
       "      \n",
       "      .. versionadded:: 1.4.0\n",
       "  \n",
       "  getWindowSize(self)\n",
       "      Gets the value of windowSize or its default value.\n",
       "      \n",
       "      .. versionadded:: 2.0.0\n",
       "  \n",
       "  setMaxSentenceLength(self, value)\n",
       "      Sets the value of :py:attr:&#96;maxSentenceLength&#96;.\n",
       "      \n",
       "      .. versionadded:: 2.0.0\n",
       "  \n",
       "  setMinCount(self, value)\n",
       "      Sets the value of :py:attr:&#96;minCount&#96;.\n",
       "      \n",
       "      .. versionadded:: 1.4.0\n",
       "  \n",
       "  setNumPartitions(self, value)\n",
       "      Sets the value of :py:attr:&#96;numPartitions&#96;.\n",
       "      \n",
       "      .. versionadded:: 1.4.0\n",
       "  \n",
       "  setParams(self, vectorSize=100, minCount=5, numPartitions=1, stepSize=0.025, maxIter=1, seed=None, inputCol=None, outputCol=None, windowSize=5, maxSentenceLength=1000)\n",
       "      setParams(self, minCount=5, numPartitions=1, stepSize=0.025, maxIter=1, seed=None,                  inputCol=None, outputCol=None, windowSize=5, maxSentenceLength=1000)\n",
       "      Sets params for this Word2Vec.\n",
       "      \n",
       "      .. versionadded:: 1.4.0\n",
       "  \n",
       "  setVectorSize(self, value)\n",
       "      Sets the value of :py:attr:&#96;vectorSize&#96;.\n",
       "      \n",
       "      .. versionadded:: 1.4.0\n",
       "  \n",
       "  setWindowSize(self, value)\n",
       "      Sets the value of :py:attr:&#96;windowSize&#96;.\n",
       "      \n",
       "      .. versionadded:: 2.0.0\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Data and other attributes defined here:\n",
       "  \n",
       "  maxSentenceLength = Param(parent=&apos;undefined&apos;, name=&apos;maxSentenceLengt.....\n",
       "  \n",
       "  minCount = Param(parent=&apos;undefined&apos;, name=&apos;minCount&apos;, doc=&quot;... be incl...\n",
       "  \n",
       "  numPartitions = Param(parent=&apos;undefined&apos;, name=&apos;numPartitions&apos;, doc=&apos;n...\n",
       "  \n",
       "  vectorSize = Param(parent=&apos;undefined&apos;, name=&apos;vectorSize&apos;, doc...imensi...\n",
       "  \n",
       "  windowSize = Param(parent=&apos;undefined&apos;, name=&apos;windowSize&apos;, doc...rds fr...\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Data and other attributes inherited from pyspark.ml.wrapper.JavaEstimator:\n",
       "  \n",
       "  __metaclass__ = &lt;class &apos;abc.ABCMeta&apos;&gt;\n",
       "      Metaclass for defining Abstract Base Classes (ABCs).\n",
       "      \n",
       "      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
       "      directly, and then acts as a mix-in class.  You can also register\n",
       "      unrelated concrete classes (even built-in classes) and unrelated\n",
       "      ABCs as &apos;virtual subclasses&apos; -- these and their descendants will\n",
       "      be considered subclasses of the registering ABC by the built-in\n",
       "      issubclass() function, but the registering ABC won&apos;t show up in\n",
       "      their MRO (Method Resolution Order) nor will method\n",
       "      implementations defined by the registering ABC be callable (not\n",
       "      even via super()).\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Methods inherited from pyspark.ml.wrapper.JavaParams:\n",
       "  \n",
       "  copy(self, extra=None)\n",
       "      Creates a copy of this instance with the same uid and some\n",
       "      extra params. This implementation first calls Params.copy and\n",
       "      then make a copy of the companion Java pipeline component with\n",
       "      extra params. So both the Python wrapper and the Java pipeline\n",
       "      component get copied.\n",
       "      \n",
       "      :param extra: Extra parameters to copy to the new instance\n",
       "      :return: Copy of this instance\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Methods inherited from pyspark.ml.wrapper.JavaWrapper:\n",
       "  \n",
       "  __del__(self)\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Data descriptors inherited from pyspark.ml.wrapper.JavaWrapper:\n",
       "  \n",
       "  __dict__\n",
       "      dictionary for instance variables (if defined)\n",
       "  \n",
       "  __weakref__\n",
       "      list of weak references to the object (if defined)\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Methods inherited from pyspark.ml.base.Estimator:\n",
       "  \n",
       "  fit(self, dataset, params=None)\n",
       "      Fits a model to the input dataset with optional parameters.\n",
       "      \n",
       "      :param dataset: input dataset, which is an instance of :py:class:&#96;pyspark.sql.DataFrame&#96;\n",
       "      :param params: an optional param map that overrides embedded params. If a list/tuple of\n",
       "                     param maps is given, this calls fit on each param map and returns a list of\n",
       "                     models.\n",
       "      :returns: fitted model(s)\n",
       "      \n",
       "      .. versionadded:: 1.3.0\n",
       "  \n",
       "  fitMultiple(self, dataset, paramMaps)\n",
       "      Fits a model to the input dataset for each param map in &#96;paramMaps&#96;.\n",
       "      \n",
       "      :param dataset: input dataset, which is an instance of :py:class:&#96;pyspark.sql.DataFrame&#96;.\n",
       "      :param paramMaps: A Sequence of param maps.\n",
       "      :return: A thread safe iterable which contains one model for each param map. Each\n",
       "               call to &#96;next(modelIterator)&#96; will return &#96;(index, model)&#96; where model was fit\n",
       "               using &#96;paramMaps[index]&#96;. &#96;index&#96; values may not be sequential.\n",
       "      \n",
       "      .. note:: DeveloperApi\n",
       "      .. note:: Experimental\n",
       "      \n",
       "      .. versionadded:: 2.3.0\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Methods inherited from pyspark.ml.param.shared.HasStepSize:\n",
       "  \n",
       "  getStepSize(self)\n",
       "      Gets the value of stepSize or its default value.\n",
       "  \n",
       "  setStepSize(self, value)\n",
       "      Sets the value of :py:attr:&#96;stepSize&#96;.\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Data and other attributes inherited from pyspark.ml.param.shared.HasStepSize:\n",
       "  \n",
       "  stepSize = Param(parent=&apos;undefined&apos;, name=&apos;stepSize&apos;, doc=&apos;...used for...\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Methods inherited from pyspark.ml.param.shared.HasMaxIter:\n",
       "  \n",
       "  getMaxIter(self)\n",
       "      Gets the value of maxIter or its default value.\n",
       "  \n",
       "  setMaxIter(self, value)\n",
       "      Sets the value of :py:attr:&#96;maxIter&#96;.\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Data and other attributes inherited from pyspark.ml.param.shared.HasMaxIter:\n",
       "  \n",
       "  maxIter = Param(parent=&apos;undefined&apos;, name=&apos;maxIter&apos;, doc=&apos;max number of...\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Methods inherited from pyspark.ml.param.shared.HasSeed:\n",
       "  \n",
       "  getSeed(self)\n",
       "      Gets the value of seed or its default value.\n",
       "  \n",
       "  setSeed(self, value)\n",
       "      Sets the value of :py:attr:&#96;seed&#96;.\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Data and other attributes inherited from pyspark.ml.param.shared.HasSeed:\n",
       "  \n",
       "  seed = Param(parent=&apos;undefined&apos;, name=&apos;seed&apos;, doc=&apos;random seed.&apos;)\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Methods inherited from pyspark.ml.param.shared.HasInputCol:\n",
       "  \n",
       "  getInputCol(self)\n",
       "      Gets the value of inputCol or its default value.\n",
       "  \n",
       "  setInputCol(self, value)\n",
       "      Sets the value of :py:attr:&#96;inputCol&#96;.\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Data and other attributes inherited from pyspark.ml.param.shared.HasInputCol:\n",
       "  \n",
       "  inputCol = Param(parent=&apos;undefined&apos;, name=&apos;inputCol&apos;, doc=&apos;input colum...\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Methods inherited from pyspark.ml.param.shared.HasOutputCol:\n",
       "  \n",
       "  getOutputCol(self)\n",
       "      Gets the value of outputCol or its default value.\n",
       "  \n",
       "  setOutputCol(self, value)\n",
       "      Sets the value of :py:attr:&#96;outputCol&#96;.\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Data and other attributes inherited from pyspark.ml.param.shared.HasOutputCol:\n",
       "  \n",
       "  outputCol = Param(parent=&apos;undefined&apos;, name=&apos;outputCol&apos;, doc=&apos;output co...\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Methods inherited from pyspark.ml.param.Params:\n",
       "  \n",
       "  explainParam(self, param)\n",
       "      Explains a single param and returns its name, doc, and optional\n",
       "      default value and user-supplied value in a string.\n",
       "  \n",
       "  explainParams(self)\n",
       "      Returns the documentation of all params with their optionally\n",
       "      default values and user-supplied values.\n",
       "  \n",
       "  extractParamMap(self, extra=None)\n",
       "      Extracts the embedded default param values and user-supplied\n",
       "      values, and then merges them with extra values from input into\n",
       "      a flat param map, where the latter value is used if there exist\n",
       "      conflicts, i.e., with ordering: default param values &lt;\n",
       "      user-supplied values &lt; extra.\n",
       "      \n",
       "      :param extra: extra param values\n",
       "      :return: merged param map\n",
       "  \n",
       "  getOrDefault(self, param)\n",
       "      Gets the value of a param in the user-supplied param map or its\n",
       "      default value. Raises an error if neither is set.\n",
       "  \n",
       "  getParam(self, paramName)\n",
       "      Gets a param by its name.\n",
       "  \n",
       "  hasDefault(self, param)\n",
       "      Checks whether a param has a default value.\n",
       "  \n",
       "  hasParam(self, paramName)\n",
       "      Tests whether this instance contains a param with a given\n",
       "      (string) name.\n",
       "  \n",
       "  isDefined(self, param)\n",
       "      Checks whether a param is explicitly set by user or has\n",
       "      a default value.\n",
       "  \n",
       "  isSet(self, param)\n",
       "      Checks whether a param is explicitly set by user.\n",
       "  \n",
       "  set(self, param, value)\n",
       "      Sets a parameter in the embedded param map.\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Data descriptors inherited from pyspark.ml.param.Params:\n",
       "  \n",
       "  params\n",
       "      Returns all params ordered by name. The default implementation\n",
       "      uses :py:func:&#96;dir&#96; to get all attributes of type\n",
       "      :py:class:&#96;Param&#96;.\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Methods inherited from pyspark.ml.util.Identifiable:\n",
       "  \n",
       "  __repr__(self)\n",
       "      Return repr(self).\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Class methods inherited from pyspark.ml.util.JavaMLReadable:\n",
       "  \n",
       "  read() from builtins.type\n",
       "      Returns an MLReader instance for this class.\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Class methods inherited from pyspark.ml.util.MLReadable:\n",
       "  \n",
       "  load(path) from builtins.type\n",
       "      Reads an ML instance from the input path, a shortcut of &#96;read().load(path)&#96;.\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Methods inherited from pyspark.ml.util.JavaMLWritable:\n",
       "  \n",
       "  write(self)\n",
       "      Returns an MLWriter instance for this ML instance.\n",
       "  \n",
       "  ----------------------------------------------------------------------\n",
       "  Methods inherited from pyspark.ml.util.MLWritable:\n",
       "  \n",
       "  save(self, path)\n",
       "      Save this ML instance to the given path, a shortcut of &apos;write().save(path)&apos;.\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "help(Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----+--------------------+----------+\n",
       "word|              vector|len_vector|\n",
       "+----+--------------------+----------+\n",
       "   a|[0.02185205556452...|       100|\n",
       "   b|[0.15395373106002...|       100|\n",
       "   c|[-0.0455951876938...|       100|\n",
       "+----+--------------------+----------+\n",
       "\n",
       "CPU times: user 24 ms, sys: 8 ms, total: 32 ms\n",
       "Wall time: 1.04 s\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "word2Vec = Word2Vec(vectorSize=100, seed=42, inputCol=\"sentence\", outputCol=\"model\",  maxIter=1)\n",
    "model = word2Vec.fit(doc)\n",
    "\n",
    "vv = model.getVectors()\n",
    "vv = vv.withColumn(\"len_vector\", len_list(vv['vector']))\n",
    "vv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----+--------------------+----------+\n",
       "word|              vector|len_vector|\n",
       "+----+--------------------+----------+\n",
       "   a|[0.06063261628150...|         5|\n",
       "   b|[1.15109908580780...|         5|\n",
       "   c|[-0.3636681437492...|         5|\n",
       "+----+--------------------+----------+\n",
       "\n",
       "CPU times: user 16 ms, sys: 4 ms, total: 20 ms\n",
       "Wall time: 646 ms\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "word2Vec = Word2Vec(vectorSize=5, seed=42, inputCol=\"sentence\", outputCol=\"model\",  maxIter=1)\n",
    "model = word2Vec.fit(doc)\n",
    "\n",
    "vv = model.getVectors()\n",
    "vv = vv.withColumn(\"len_vector\", len_list(vv['vector']))\n",
    "vv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----+--------------------+----------+\n",
       "word|              vector|len_vector|\n",
       "+----+--------------------+----------+\n",
       "   a|[-0.0391055643558...|       100|\n",
       "   b|[0.15813410282135...|       100|\n",
       "   c|[-0.0872000753879...|       100|\n",
       "+----+--------------------+----------+\n",
       "\n",
       "CPU times: user 16 ms, sys: 4 ms, total: 20 ms\n",
       "Wall time: 1.42 s\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "word2Vec = Word2Vec(vectorSize=100, seed=42, inputCol=\"sentence\", outputCol=\"model\",  maxIter=5)\n",
    "model = word2Vec.fit(doc)\n",
    "\n",
    "vv = model.getVectors()\n",
    "vv = vv.withColumn(\"len_vector\", len_list(vv['vector']))\n",
    "vv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----+--------------------+----------+\n",
       "word|              vector|len_vector|\n",
       "+----+--------------------+----------+\n",
       "   a|[-0.0573107227683...|       100|\n",
       "   b|[0.13437749445438...|       100|\n",
       "   c|[-0.0847115665674...|       100|\n",
       "+----+--------------------+----------+\n",
       "\n",
       "CPU times: user 12 ms, sys: 8 ms, total: 20 ms\n",
       "Wall time: 1.35 s\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "word2Vec = Word2Vec(vectorSize=100, seed=42, inputCol=\"sentence\", outputCol=\"model\",  maxIter=10)\n",
    "model = word2Vec.fit(doc)\n",
    "\n",
    "vv = model.getVectors()\n",
    "vv = vv.withColumn(\"len_vector\", len_list(vv['vector']))\n",
    "vv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----+--------------------+----------+\n",
       "word|              vector|len_vector|\n",
       "+----+--------------------+----------+\n",
       "   a|[0.02185205556452...|       100|\n",
       "   b|[0.15395373106002...|       100|\n",
       "   c|[-0.0455951876938...|       100|\n",
       "+----+--------------------+----------+\n",
       "\n",
       "CPU times: user 20 ms, sys: 8 ms, total: 28 ms\n",
       "Wall time: 1 s\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "word2Vec = Word2Vec(vectorSize=100, seed=42, inputCol=\"sentence\", outputCol=\"model\",  maxIter=1, numPartitions=1)\n",
    "model = word2Vec.fit(doc)\n",
    "\n",
    "vv = model.getVectors()\n",
    "vv = vv.withColumn(\"len_vector\", len_list(vv['vector']))\n",
    "vv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----+--------------------+----------+\n",
       "word|              vector|len_vector|\n",
       "+----+--------------------+----------+\n",
       "   a|[0.01315427385270...|       100|\n",
       "   b|[0.30133217573165...|       100|\n",
       "   c|[-0.0930862948298...|       100|\n",
       "+----+--------------------+----------+\n",
       "\n",
       "CPU times: user 16 ms, sys: 8 ms, total: 24 ms\n",
       "Wall time: 820 ms\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "word2Vec = Word2Vec(vectorSize=100, seed=42, inputCol=\"sentence\", outputCol=\"model\",  maxIter=1, numPartitions=2)\n",
    "model = word2Vec.fit(doc)\n",
    "\n",
    "vv = model.getVectors()\n",
    "vv = vv.withColumn(\"len_vector\", len_list(vv['vector']))\n",
    "vv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "ProofJupy",
  "notebookId": 2352177274545271
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
