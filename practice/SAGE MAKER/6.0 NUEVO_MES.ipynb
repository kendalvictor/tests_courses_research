{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88c59878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (3.2.1)\n",
      "Requirement already satisfied: awswrangler in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.9.0)\n",
      "Requirement already satisfied: pyarrow<4.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (4.0.0)\n",
      "Requirement already satisfied: pandas<1.3.0,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.1.5)\n",
      "Requirement already satisfied: numpy<1.21.0,>=1.18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.19.5)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.16.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.17.76)\n",
      "Requirement already satisfied: pymysql<1.1.0,>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.0.2)\n",
      "Requirement already satisfied: pg8000<1.20.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.19.5)\n",
      "Requirement already satisfied: openpyxl~=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (3.0.6)\n",
      "Requirement already satisfied: redshift-connector~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (2.0.882)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.19.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.20.76)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3<2.0.0,>=1.16.8->awswrangler) (0.4.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3<2.0.0,>=1.16.8->awswrangler) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<2.0.0,>=1.19.8->awswrangler) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<2.0.0,>=1.19.8->awswrangler) (1.26.4)\n",
      "Requirement already satisfied: et-xmlfile in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from openpyxl~=3.0.0->awswrangler) (1.0.1)\n",
      "Requirement already satisfied: jdcal in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from openpyxl~=3.0.0->awswrangler) (1.4.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas<1.3.0,>=1.1.0->awswrangler) (2021.1)\n",
      "Requirement already satisfied: scramp==1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pg8000<1.20.0,>=1.16.0->awswrangler) (1.4.0)\n",
      "Requirement already satisfied: asn1crypto==1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scramp==1.4.0->pg8000<1.20.0,>=1.16.0->awswrangler) (1.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.19.8->awswrangler) (1.15.0)\n",
      "Requirement already satisfied: requests<2.25.2,>=2.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from redshift-connector~=2.0.0->awswrangler) (2.25.1)\n",
      "Requirement already satisfied: lxml>=4.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from redshift-connector~=2.0.0->awswrangler) (4.6.3)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from redshift-connector~=2.0.0->awswrangler) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from beautifulsoup4<5.0.0,>=4.7.0->redshift-connector~=2.0.0->awswrangler) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.25.2,>=2.23.0->redshift-connector~=2.0.0->awswrangler) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.25.2,>=2.23.0->redshift-connector~=2.0.0->awswrangler) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.25.2,>=2.23.0->redshift-connector~=2.0.0->awswrangler) (2.10)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from lightgbm) (0.36.2)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from lightgbm) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from lightgbm) (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pip\n",
    "\n",
    "package_names = ['lightgbm', 'awswrangler'] \n",
    "pip.main(['install'] + package_names + ['--upgrade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d23ba40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nativos\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from time import gmtime, strftime\n",
    "from datetime import datetime\n",
    "import random as rn\n",
    "import joblib\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "\n",
    "#nube\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker import get_execution_role\n",
    "import awswrangler as wr\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "#calculo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "#grafico\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "#Interacciones con output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "gc.collect()\n",
    "# MODELS\n",
    "from lightgbm import LGBMClassifier\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.svm import LinearSVC\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier \n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn import metrics\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.getcwd())\n",
    "if BASE_DIR not in sys.path: sys.path.append(BASE_DIR)\n",
    "#import scorecardpy as sc\n",
    "#from utils import *\n",
    "#from graphs import *\n",
    "\n",
    "SEED = 29082013\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)\n",
    "\n",
    "#from utils import *\n",
    "#from modeler import *\n",
    "#subfolder = \"data\"\n",
    "# os.listdir(subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cd083f",
   "metadata": {},
   "source": [
    "### CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7274e606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-058528764918 \n",
      " 2021-05-01 \n",
      " 202105\n"
     ]
    }
   ],
   "source": [
    "desfase = 1\n",
    "proyecto = 'trading'\n",
    "responsable = 'victor'\n",
    "now = datetime.now()\n",
    "sess = sagemaker.session.Session()\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = sess.default_bucket() \n",
    "region = boto3.Session().region_name\n",
    "\n",
    "ultimo_mes =  datetime.strptime((now - relativedelta(months=desfase)).strftime('%Y-%m'), '%Y-%m').strftime('%Y-%m-%d')\n",
    "ultimo_periodo = ultimo_mes.replace('-', '')[:6]\n",
    "\n",
    "print(bucket, '\\n',ultimo_mes, '\\n', ultimo_periodo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de34c269",
   "metadata": {},
   "source": [
    "### HABILITADO RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9c2a6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_origin:  vpc/trading/victor/INPUTS/INPUT_202105.csv\n",
      "key_inputs:  vpc/trading/victor/RAW/INPUT.csv\n",
      "path_share:  s3://sagemaker-us-east-1-058528764918/vpc/trading/victor/RAW\n",
      "path_outputs:  s3://sagemaker-us-east-1-058528764918/vpc/trading/victor/OUPUT\n"
     ]
    }
   ],
   "source": [
    "key_origin = 'vpc/{}/{}/INPUTS/INPUT_{}.csv'.format(proyecto, responsable, ultimo_periodo)\n",
    "key_share = 'vpc/{}/{}/RAW/INPUT.csv'.format(proyecto, responsable)\n",
    "path_share = 's3://{}/vpc/{}/{}/RAW'.format(bucket, proyecto, responsable)\n",
    "path_outputs = 's3://{}/vpc/{}/{}/OUPUT'.format(bucket, proyecto, responsable)\n",
    "\n",
    "s3.meta.client.copy({\n",
    "    'Bucket': bucket,\n",
    "    'Key': key_origin\n",
    "},\n",
    "    bucket,\n",
    "    key_share\n",
    ")\n",
    "\n",
    "print('key_origin: ', key_origin)\n",
    "print('key_inputs: ', key_share)\n",
    "print('path_share: ', path_share)\n",
    "print('path_outputs: ', path_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee23aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = wr.s3.read_csv(path_inputs, sep=',', encoding='ISO-8859-1', dtype=dicc_str)\n",
    "#print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c2752f",
   "metadata": {},
   "source": [
    "### PROCESAMIENTO DESACOPLADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "108c6e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same images used for training and inference. Defaulting to image scope: inference.\n",
      "Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "processing_tags = [{'Key': 'cost-center', 'Value': 'TF2WorkflowProcessing'}]\n",
    "\n",
    "sklearn_processor1 = SKLearnProcessor(\n",
    "    framework_version='0.23-1',\n",
    "    role=get_execution_role(),\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=1,\n",
    "    tags=processing_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8ee33b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing read_test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile read_test.py\n",
    "\n",
    "#nativos\n",
    "import random as rn\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "#calculo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "#terceros\n",
    "import pip\n",
    "\n",
    "package_names = ['lightgbm']\n",
    "pip.main(['install'] + package_names + ['--upgrade']) \n",
    "\n",
    "SEED = 29082013\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    path_input = '/opt/ml/processing/input'\n",
    "\n",
    "    for csvname in glob.iglob('{}/*.json'.format(path_input), recursive=True):\n",
    "        with open(csvname, 'r') as name_file:\n",
    "            _dict = json.load(name_file)\n",
    "            outfile_name = name_file.replace('input', 'output')\n",
    "            \n",
    "            with open(outfile_name, 'w+') as outfile:\n",
    "                json.dump(_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ec8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  trading-workflow-2021-06-25-01-34-50\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-058528764918/vpc/trading/victor/RAW', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'ShardedByS3Key', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-058528764918/trading-workflow-2021-06-25-01-34-50/input/code/read_test.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'result', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-058528764918/vpc/trading/victor/OUPUT', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "Creating processing-job with name trading-workflow-2021-06-25-01-34-50\n",
      "...."
     ]
    }
   ],
   "source": [
    "processing_job_name = \"trading-workflow-{}\".format(strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()))\n",
    "path_input = '/opt/ml/processing/input'\n",
    "path_output = path_input.replace('input', 'output')\n",
    "\n",
    "sklearn_processor1.run(\n",
    "    code='read_test.py',\n",
    "    job_name=processing_job_name,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=path_share,\n",
    "            destination=path_input,\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name='result',\n",
    "            destination=path_outputs,\n",
    "            source=path_output\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessing_job_description = sklearn_processor1.jobs[-1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e74fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1b522a2",
   "metadata": {},
   "source": [
    "### CARGA NUEVO INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bbe9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dicc_str = {\n",
    "    'NUM_RUC': str, \n",
    "    'COD_UNICO': str, \n",
    "    'PERIODO': str, \n",
    "    'TIPDOC': str,\n",
    "    'CODDOC': str\n",
    "}\n",
    "\n",
    "def tendencia_trading(lista, minimo=0):\n",
    "    media_trim = np.mean(lista[-3:])\n",
    "    \n",
    "    if lista[-6] == -1 and lista[-5] == -1 and lista[-4] == -1 and lista[-3] == -1 and lista[-2] == -1:\n",
    "        return int(lista[-1] > minimo)\n",
    "    elif lista[-6] == -1 and lista[-5] == -1 and lista[-4] == -1 and lista[-3] == -1:\n",
    "        return int(np.mean(lista[-2:]) > minimo)\n",
    "    elif lista[-6] == -1 and lista[-5] == -1 and lista[-4] == -1:\n",
    "        return int(np.mean(lista[-3:]) > minimo)\n",
    "    elif lista[-6] == -1 and lista[-5] == -1:\n",
    "        median_pasado = lista[-4]\n",
    "    elif lista[-6] == -1:\n",
    "        median_pasado = np.mean(lista[-5:-3])\n",
    "    else:\n",
    "        median_pasado = np.mean(lista[-6:-3])\n",
    "        \n",
    "    if media_trim <= minimo and median_pasado <= minimo:\n",
    "        return 0\n",
    "    elif median_pasado <= minimo:\n",
    "        return 1.01\n",
    "\n",
    "    return media_trim / median_pasado\n",
    "\n",
    "def div_fix(a, b, minimo=0.001):\n",
    "    if a + b == 0:\n",
    "        return 0\n",
    "    if a < minimo and b < minimo:\n",
    "        return 0\n",
    "    elif b == 0:\n",
    "        return 1\n",
    "    \n",
    "    return a / b\n",
    "\n",
    "def search_especific_o_menor(lista, wanted):\n",
    "    meses = 0\n",
    "    for val in lista[::-1]:\n",
    "        if val <= wanted:\n",
    "            return meses\n",
    "        meses += 1\n",
    "    \n",
    "    return meses\n",
    "\n",
    "def generate_listado_historico(data, col_name='listado', values='VOLUMEN_TRADING_MES', \n",
    "                               index=['COD_UNICO'], columns=['PERIODO'], fill=0,\n",
    "                               aggfunc=np.sum, tramos=[]):\n",
    "    \n",
    "    pivoteo = pd.pivot_table(\n",
    "        data, \n",
    "        values=values, index=index, columns=columns, aggfunc=aggfunc, fill_value=fill\n",
    "    ).unstack().reset_index()\n",
    "    \n",
    "    pivoteo.columns = columns + index + [col_name]\n",
    "    \n",
    "    contador = 1\n",
    "    dicc = {col_name: list}\n",
    "    \n",
    "    for tramo in tramos:\n",
    "        _6_meses_previos = tramo[1]\n",
    "        print(tramo[0], _6_meses_previos)\n",
    "        \n",
    "        _6m_actual = pivoteo[pivoteo['PERIODO'].astype(int).isin(_6_meses_previos)].groupby(by=index).agg(dicc)\n",
    "        \n",
    "        _6m_actual = _6m_actual.reset_index().rename(columns={'index': index[0]})\n",
    "        _6m_actual['PERIODO'] = tramo[0]\n",
    "\n",
    "        if contador == 1:\n",
    "            acum_6 = _6m_actual.copy()\n",
    "        else:\n",
    "            acum_6 = pd.concat(\n",
    "                [acum_6, _6m_actual], axis=0, ignore_index=True\n",
    "            )\n",
    "\n",
    "        print(acum_6.shape)\n",
    "        contador +=1\n",
    "        del _6m_actual\n",
    "        \n",
    "    del pivoteo\n",
    "    return acum_6\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print(\"/\"*50, 'CARGA')\n",
    "    data = pd.read_csv(path_inputs, sep=',', encoding='ISO-8859-1', dtype=dicc_str)\n",
    "    print(data.shape)\n",
    "    cols_del = [col for col in data.columns if ('TARGET' in col.upper() or 'FUTURO' in col.upper())]\n",
    "    print(len(cols_del))\n",
    "\n",
    "    print(data.shape)\n",
    "    data = data.drop(cols_del, axis=1)\n",
    "    print(data.shape)\n",
    "    print(\"/\"*50)\n",
    "\n",
    "\n",
    "    print(\"/\"*50, 'IMPUTACION')\n",
    "    cols_id = ['COD_UNICO', 'PERIODO','CODDOC', 'NUM_RUC']\n",
    "    print(len(cols_id))\n",
    "\n",
    "    cols_num = [col for col in data.describe().T.index if col not in cols_id]\n",
    "    print(len(cols_num))\n",
    "\n",
    "    cols_str = [col for col in data.describe(include=[object, bool]).T.index if col not in cols_id]\n",
    "    print(len(cols_str))\n",
    "\n",
    "    nulls = data.isnull().sum()\n",
    "    cols_nulls = nulls[nulls > 0].index\n",
    "\n",
    "    for col in cols_nulls:\n",
    "\n",
    "        if col in cols_num:\n",
    "            data[col] = data[col].fillna(0)\n",
    "            print(\"num: \", end=' ')\n",
    "\n",
    "        elif col in cols_str:\n",
    "            data[col] = data[col].fillna('DESCONOCIDO')\n",
    "            print(\"cat: \", end=' ')\n",
    "\n",
    "        print(col)\n",
    "    print(\"/\"*50)\n",
    "\n",
    "\n",
    "    print(\"/\"*50, 'VARIABLES HISTORICAS')\n",
    "    tramo_actual = []\n",
    "    rango_actual =  [_ for _ in list(pd.date_range(ultimo_mes, ultimo_mes, freq='MS'))]\n",
    "    print(rango_actual)\n",
    "\n",
    "    for periodo_base in rango_actual:\n",
    "\n",
    "        rango_ = [\n",
    "            int(_.strftime('%Y%m')) for _ in list(\n",
    "                pd.date_range((periodo_base - relativedelta(months=8)), (periodo_base), freq='MS')\n",
    "            )\n",
    "        ]\n",
    "        tramo_actual.append(\n",
    "            (int(periodo_base.strftime('%Y%m')),           #mes cosecha\n",
    "             rango_,  # listado 14 periodos sumando dos adelante y restando 11 periodos atras\n",
    "             [rango_[0]],     #hace 6 meses\n",
    "             [rango_[-1]])    #mes actual\n",
    "        )\n",
    "\n",
    "        print(tramo_actual[0][0], tramo_actual[0][1])\n",
    "        print(tramo_actual[0][2], tramo_actual[0][3])\n",
    "    print(\"/\"*50)\n",
    "\n",
    "\n",
    "    print(\"/\"*50, 'CANTIDAD TRADING')\n",
    "    acum_6 = generate_listado_historico(data, col_name='listado', values='CNT_TRADING_MES', fill=-1, tramos=tramo_actual)\n",
    "    print(acum_6.shape)\n",
    "    acum_6['no_habilitado_este_mes'] = acum_6['listado'].apply(lambda _: _[-1] == -1).astype(int)\n",
    "    acum_6 = acum_6[acum_6['no_habilitado_este_mes'] == 0]\n",
    "\n",
    "    del acum_6['no_habilitado_este_mes']\n",
    "    print(acum_6.shape)\n",
    "\n",
    "    acum_6['meses_habilitado_para_trading'] = acum_6['listado'].apply(lambda _: len([mes for mes in _ if mes != -1]))\n",
    "    acum_6['meses_trading_consecutivo'] = acum_6['listado'].apply(lambda _: search_especific_o_menor(_, 0))\n",
    "    acum_6['meses_con_trading_U9M'] = acum_6['listado'].apply(lambda _: len([mes for mes in _ if mes > 0]))\n",
    "    acum_6['ratio_frecuencia_trading_U9M'] = acum_6[['meses_con_trading_U9M', 'meses_habilitado_para_trading']].apply(lambda _: div_fix(_[0], _[1]), axis=1)\n",
    "    acum_6['ratio_frecuencia_consecutiva_trading_U9M'] = acum_6[['meses_trading_consecutivo', 'meses_habilitado_para_trading']].apply(lambda _: div_fix(_[0], _[1]), axis=1)\n",
    "    acum_6['tiene_6_o_mas_meses_habilitado'] = acum_6['meses_habilitado_para_trading'].apply(lambda _: _ >= 6).astype(int)\n",
    "    acum_6['tiene_recien_3_o menos_meses_habilitado'] = acum_6['meses_habilitado_para_trading'].apply(lambda _: _ <= 3).astype(int)\n",
    "    acum_6['tiene_recien_mas_de_3_meses_habilitado'] = acum_6['meses_habilitado_para_trading'].apply(lambda _: _ > 3).astype(int)\n",
    "    acum_6['cnt_trading_hist_U6M'] = acum_6['listado'].apply(lambda _: np.sum([mes for mes in _[-6:] if mes > 0]))\n",
    "    acum_6['cnt_trading_hist_U3M'] = acum_6['listado'].apply(lambda _: np.sum([mes for mes in _[-3:] if mes > 0]))\n",
    "    acum_6['mean_cant_trading_U6M'] = acum_6['listado'].apply(lambda _: np.mean([mes for mes in _[-6:] if mes >= 0]))\n",
    "    acum_6['median_cant_trading_U6M'] = acum_6['listado'].apply(lambda _: np.median([mes for mes in _[-6:] if mes >= 0]))\n",
    "    acum_6['std_cant_trading_U6M'] = acum_6['listado'].apply(lambda _: np.std([mes for mes in _[-6:] if mes >= 0]))\n",
    "    acum_6['tendencia_cant_trading_trimult_over_trimpasado_U6M'] = acum_6['listado'].apply(lambda _: tendencia_trading(_[-6:]))\n",
    "    del acum_6['listado']\n",
    "    acum_6.to_csv('HISTORICO_CANTIDAD_TRADING_ULTIMO_PERIODO.csv', index=False)\n",
    "    print(\"/\"*50)\n",
    "\n",
    "\n",
    "    print(\"/\"*50, 'MONTO TRADING')\n",
    "    acum_6 = generate_listado_historico(data, col_name='listado', values='VOLUMEN_TRADING_MES', fill=-1, tramos=tramo_actual)\n",
    "    print(acum_6.shape)\n",
    "    acum_6['no_habilitado_este_mes'] = acum_6['listado'].apply(lambda _: _[-1] == -1).astype(int)\n",
    "    acum_6 = acum_6[acum_6['no_habilitado_este_mes'] == 0]\n",
    "\n",
    "    del acum_6['no_habilitado_este_mes']\n",
    "    print(acum_6.shape)\n",
    "\n",
    "    acum_6['nro_meses_trading_hist_U6M'] = acum_6['listado'].apply(lambda _: len([mes for mes in _[-6:] if mes > 0]))\n",
    "    acum_6['nro_meses_trading_up_100_hist_U6M'] = acum_6['listado'].apply(lambda _: len([mes for mes in _[-6:] if mes > 100]))\n",
    "    acum_6['nro_meses_trading_up_1000_hist_U6M'] = acum_6['listado'].apply(lambda _: len([mes for mes in _[-6:] if mes > 1000]))\n",
    "    acum_6['mean_trading_hist_U6M'] = acum_6['listado'].apply(lambda _: np.mean([mes for mes in _[-6:] if mes >= 0]))\n",
    "    acum_6['median_trading_hist_U6M'] = acum_6['listado'].apply(lambda _: np.median([mes for mes in _[-6:] if mes >= 0]))\n",
    "    acum_6['std_trading_hist_U6M'] = acum_6['listado'].apply(lambda _: np.std([mes for mes in _[-6:] if mes >= 0]))\n",
    "\n",
    "    acum_6['tendencia_monto_trading_trimult_over_trimpasado'] = acum_6['listado'].apply(lambda _: tendencia_trading(_[-6:]))\n",
    "    acum_6['tendencia_monto_up_100_trading_trimult_over_trimpasado'] = acum_6['listado'].apply(lambda _: tendencia_trading(_[-6:], 99.99))\n",
    "    acum_6['tendencia_monto_up_1000_trading_trimult_over_trimpasado'] = acum_6['listado'].apply(lambda _: tendencia_trading(_[-6:], 999.99))\n",
    "\n",
    "    del acum_6['listado']\n",
    "    acum_6.to_csv('HISTORICO_MONTO_TRADING_ULTIMO_PERIODO.csv', index=False)\n",
    "    del acum_6\n",
    "    gc.collect()\n",
    "    print(\"/\"*50)\n",
    "\n",
    "\n",
    "    print(\"/\"*50, 'NIVELADO')\n",
    "    periodos_cosecha = [_[0] for _ in tramo_actual]\n",
    "    print(periodos_cosecha)\n",
    "\n",
    "    data = data[data['PERIODO'].astype(int).isin(periodos_cosecha)]\n",
    "    data['PERIODO'] = data['PERIODO'].astype(str)\n",
    "    data['COD_UNICO'] = data['COD_UNICO'].astype(str)\n",
    "\n",
    "    cantidades = pd.read_csv('HISTORICO_CANTIDAD_TRADING_ULTIMO_PERIODO.csv',  dtype={'COD_UNICO': str, 'PERIODO': str})\n",
    "\n",
    "    print(data.shape)\n",
    "    data = data.merge(\n",
    "        cantidades, on=['COD_UNICO', 'PERIODO'], how='left'\n",
    "    )\n",
    "    print(data.shape)\n",
    "    del cantidades\n",
    "    gc.collect()\n",
    "\n",
    "    monto = pd.read_csv('HISTORICO_MONTO_TRADING_ULTIMO_PERIODO.csv',  dtype={'COD_UNICO': str, 'PERIODO': str})\n",
    "\n",
    "    print(data.shape)\n",
    "    data = data.merge(\n",
    "        monto, on=['COD_UNICO', 'PERIODO'], how='left'\n",
    "    )\n",
    "    print(data.shape)\n",
    "    del monto\n",
    "    gc.collect()\n",
    "    print(\"/\"*50)\n",
    "\n",
    "    print(\"/\"*50, 'CORRECCION CAMPOS NEGACION')\n",
    "    data['FLG_NO_TRADING_U2M'] = data[['FLG_NO_TRADING_U3M', 'meses_habilitado_para_trading']].apply(lambda _: 0 if _[1] < 2 and _[0] == 1 else _[0], axis=1)\n",
    "    data['FLG_NO_TRADING_U3M'] = data[['FLG_NO_TRADING_U3M', 'meses_habilitado_para_trading']].apply(lambda _: 0 if _[1] < 3 and _[0] == 1 else _[0], axis=1)\n",
    "    data['FLG_NO_TRADING_U4M'] = data[['FLG_NO_TRADING_U4M', 'meses_habilitado_para_trading']].apply(lambda _: 0 if _[1] < 4 and _[0] == 1 else _[0], axis=1)\n",
    "    data['FLG_NO_TRADING_U5M'] = data[['FLG_NO_TRADING_U5M', 'meses_habilitado_para_trading']].apply(lambda _: 0 if _[1] < 5 and _[0] == 1 else _[0], axis=1)\n",
    "    data['FLG_NO_TRADING_U6M'] = data[['FLG_NO_TRADING_U6M', 'meses_habilitado_para_trading']].apply(lambda _: 0 if _[1] < 6 and _[0] == 1 else _[0], axis=1)\n",
    "    data['FLG_NO_TRADING_U7M'] = data[['FLG_NO_TRADING_U7M', 'meses_habilitado_para_trading']].apply(lambda _: 0 if _[1] < 7 and _[0] == 1 else _[0], axis=1)\n",
    "    data['FLG_NO_TRADING_U8M'] = data[['FLG_NO_TRADING_U8M', 'meses_habilitado_para_trading']].apply(lambda _: 0 if _[1] < 8 and _[0] == 1 else _[0], axis=1)\n",
    "    data['FLG_NO_TRADING_U9M'] = data[['FLG_NO_TRADING_U9M', 'meses_habilitado_para_trading']].apply(lambda _: 0 if _[1] < 9 and _[0] == 1 else _[0], axis=1)\n",
    "    print(\"/\"*50)\n",
    "\n",
    "    print(\"/\"*50, 'TRATAMIENTO DE CATEGORICOS')\n",
    "    for col in cols_str:\n",
    "        if col in data.columns:\n",
    "            print(col)\n",
    "            size = data[col].unique().shape[0]\n",
    "\n",
    "            if size == 1:\n",
    "                del data[col]\n",
    "\n",
    "            elif size == 2:\n",
    "                data = pd.get_dummies(data, columns=[col], drop_first=True)\n",
    "\n",
    "            elif size <= 9:\n",
    "                data = pd.get_dummies(data, columns=[col], drop_first=False)\n",
    "\n",
    "    data['LIMA_CALLAO'] = data['DEPARTAMENTO'].apply(lambda _: _ in ['LIMA', 'CALLAO']).astype(int)\n",
    "    data['LIMA_CALLAO_ICA_TACNA'] = data['DEPARTAMENTO'].apply(lambda _: _ in ['LIMA', 'CALLAO', 'ICA', 'TACNA']).astype(int)\n",
    "    data['INMOBILIARIO_OTROS_AUTOMOTRIZ_MINERIA'] = data['SEI_MCDO'].apply(\n",
    "        lambda _: _ in 'INMOBILIARIO%,%OTROS%,%AUTOMOTRIZ VEHÍCULOS%,%MINERÍA'\n",
    "    ).astype(int)\n",
    "\n",
    "    if 'FEC_INGRESO' in data.columns:\n",
    "        del data['FEC_INGRESO']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f3729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd317a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89a7571c",
   "metadata": {},
   "source": [
    "### CORRECCION CAMPOS NEGACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f6a57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc8663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3786551",
   "metadata": {},
   "source": [
    "### TRATAMIENTO DE CATEGORICOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4962019f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a1c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b76cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720cb085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb190cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_str = [col for col in data.describe(include=[object, bool]).T.index if col not in cols_id]\n",
    "print(cols_str)\n",
    "len(cols_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_cat in cols_str:\n",
    "    with open('encoder_target_{}.json'.format(col_cat.lower()), 'r') as name_file:\n",
    "        _dict = json.load(name_file)\n",
    "        print(col_cat)\n",
    "        \n",
    "        for target in [col_target_0, col_target_100, col_target_1000]:\n",
    "            name = col_cat + '_encoder_' + target.replace('TARGET_TRADING', '')\n",
    "            data[name] = data[col_cat].map(_dict[target])\n",
    "            print(name, end=' ')\n",
    "            \n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16445ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5fca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46108649",
   "metadata": {},
   "source": [
    "### MODELO 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb6b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_select_100 = [\n",
    "    'nro_meses_trading_up_100_hist_U6M', 'ES_ACTIVO_S', 'VOLUMEN_TRADING_MES', 'ratio_frecuencia_trading_U9M',\n",
    "    'FLG_TRADING_U3M_CONSECUTIVOS', 'CNT_CUENTAS_DOLARES', 'CNT_CUENTAS_VISTA', 'REACTIVA_IBK',\n",
    "    'SALDO_CUENTA_US', 'SALDO_PROM_SOL_TOT', 'IMPORTE_SOL_TRANSF', 'CONTEO_ADEX',\n",
    "    'DEPARTAMENTO_encoder__MAYOR_100', 'SEI_MCDO_encoder__MAYOR_100'\n",
    "]\n",
    "model_100 = joblib.load('{}/2_lgbmclassifier_20210623095243.pkl'.format(col_target_100))\n",
    "print(len(cols_select_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia_modelo_100 = pd.DataFrame({\n",
    "    'vars': cols_select_100, \n",
    "    'imp':list(model_100.feature_importances_)\n",
    "}).sort_values(\n",
    "    by=['imp'], \n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "sns.barplot(x=\"imp\", y=\"vars\", data=importancia_modelo_100, palette=\"mako\")  #mako"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65bf119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ebd6ae1",
   "metadata": {},
   "source": [
    "### Modelo 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_select_1000 = [\n",
    "    'nro_meses_trading_up_1000_hist_U6M', 'FLG_TRADING_U3M_CONSECUTIVOS',\n",
    "    'IMPORTE_SOL_TRANSF', 'VOLUMEN_DOL_FISICO', 'CNT_CUENTAS_VISTA', 'CNT_CUENTAS_AHORRO', 'SALDO_CUENTA_US',\n",
    "    'SALDO_PROM_SOL_TOT', 'tendencia_monto_up_1000_trading_trimult_over_trimpasado',\n",
    "    'MONTO_IMPORTACION', 'DEPARTAMENTO_encoder__MAYOR_1000', 'SEI_MCDO_encoder__MAYOR_1000',\n",
    "    'VOLUMEN_TRADING_MES', 'ES_ACTIVO_S'\n",
    "]\n",
    "model_1000 = joblib.load('{}/2_lgbmclassifier_20210624013237.pkl'.format(col_target_1000))\n",
    "print(len(cols_select_1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b57647",
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia_modelo_1000 = pd.DataFrame({\n",
    "    'vars': cols_select_1000, \n",
    "    'imp':list(model_1000.feature_importances_)\n",
    "}).sort_values(\n",
    "    by=['imp'], \n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "sns.barplot(x=\"imp\", y=\"vars\", data=importancia_modelo_1000, palette=\"mako\")  #mako"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a6834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4dd0b9e",
   "metadata": {},
   "source": [
    "### PREDICCION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a77a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = data[['PERIODO', 'COD_UNICO', 'cnt_trading_hist_U6M']]\n",
    "data_100 = data[cols_select_100]\n",
    "data_1000 = data[cols_select_1000]\n",
    "\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6b40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base['SCORE_100'] = model_100.predict_proba(data_100)[:,1]\n",
    "base['SCORE_1000'] = model_1000.predict_proba(data_1000)[:,1]\n",
    "\n",
    "del data_100\n",
    "del data_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a34d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "base['FRECUENCIA_0'] = base['cnt_trading_hist_U6M'].apply(lambda _: 'sin_trading' if _ == 0 else 'al_menos_1_trading')\n",
    "base['FRECUENCIA_3'] = base['cnt_trading_hist_U6M'].apply(lambda _: '3_o_mas' if _ >= 3 else 'menos_de_3')\n",
    "\n",
    "base['GRUPO_100'] = list(pd.qcut(base['SCORE_100'], cortes_deciles, labels=grupos_score))\n",
    "base['GRUPO_1000'] = list(pd.qcut(base['SCORE_1000'], cortes_deciles, labels=grupos_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1775a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base['GRUPO_CONCATENADO'] = base['GRUPO_100'] + base['GRUPO_1000']\n",
    "pd.crosstab(\n",
    "    base['GRUPO_100'], base['GRUPO_1000']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf2bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "base['GRUPO_FINAL'] = base['GRUPO_CONCATENADO'].apply(grupo_final)\n",
    "base['GRUPO_FINAL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6655c9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23e83191",
   "metadata": {},
   "source": [
    "## CRUCES CON FRECUENCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3825f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    base['FRECUENCIA_0'], base['GRUPO_FINAL']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91539ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    base['FRECUENCIA_3'], base['GRUPO_FINAL']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c36c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "181b235a",
   "metadata": {},
   "source": [
    "### GUARDADO BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f543f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base['PERIODO'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.to_excel('BASE_TRADING_{}.xlsx'.format(base['PERIODO'].max()), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be8e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
