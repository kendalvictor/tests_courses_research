{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('10', '03')\n",
      "CREATE INDEX\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "u\"cannot resolve '`IDX`' given input columns: [];;\\n'Project ['IDX]\\n+- AnalysisBarrier\\n      +- Project\\n         +- Project [Op#872, TIPOID#873, NUMID#874, DVID#875, NOMTER#876, APETER#877, CODPAIS#878, CODESTADO#879, CODCIUDAD#880, CODMUNICIPIO#881, DIREC#882, TELEF1#883, TELEF2#884, TELEF3#885, FAX#886, TELEX#887, ZIP#888, INDNACIONAL#889, STSTER#890, FECSTS#891, NUMCTAAUXI#892, TIPOTER#893, MIGRADO#894, APEMATTER#895, NOMCENTRAB#896, DIRECTRAB#897, CODPAISTRAB#898, CODESTADOTRAB#899, CODCIUDADTRAB#900, CODMUNICIPIOTRAB#901, TELEF1TRAB#902, TELEF2TRAB#903, ANEXOTRAB#904, FAXTRAB#905, CODZONAPOSTALTRAB#906, NACIONALIDAD#907, NOMCORREO#908, ZONACOB#909, SITLAB#910, PROFESION#911, TAMEMPRESA#912, SEXO#913, FECNAC#914, FECCREA#915, USUCREA#916, FECMOD#917, USUMOD#918, ESTCIVIL#919, INDASEGVIDA#920, CODACT#921, CIIU#922, CODZONAPOSTAL#923, INDDIRCOB#924, INDDIRDESP#925, CELULAR#926, RADIO#927, INDEXONERADO#928, REFERDIREC#929, REFERDIRECTRAB#930, TELEXTRABAJO#931, INDTELEX#932, SEGCOMP#933, EMAILFACTELEC#934, EMAILFACTELECCC#935, UPLOAD_BLOCK_PROCESS#936, UPLOAD_PROCESS_DATE#937, FILENAME#938, REFEXTERNA#939, monotonically_increasing_id() AS iDX#1008L]\\n            +- Relation[Op#872,TIPOID#873,NUMID#874,DVID#875,NOMTER#876,APETER#877,CODPAIS#878,CODESTADO#879,CODCIUDAD#880,CODMUNICIPIO#881,DIREC#882,TELEF1#883,TELEF2#884,TELEF3#885,FAX#886,TELEX#887,ZIP#888,INDNACIONAL#889,STSTER#890,FECSTS#891,NUMCTAAUXI#892,TIPOTER#893,MIGRADO#894,APEMATTER#895,NOMCENTRAB#896,DIRECTRAB#897,CODPAISTRAB#898,CODESTADOTRAB#899,CODCIUDADTRAB#900,CODMUNICIPIOTRAB#901,TELEF1TRAB#902,TELEF2TRAB#903,ANEXOTRAB#904,FAXTRAB#905,CODZONAPOSTALTRAB#906,NACIONALIDAD#907,NOMCORREO#908,ZONACOB#909,SITLAB#910,PROFESION#911,TAMEMPRESA#912,SEXO#913,FECNAC#914,FECCREA#915,USUCREA#916,FECMOD#917,USUMOD#918,ESTCIVIL#919,INDASEGVIDA#920,CODACT#921,CIIU#922,CODZONAPOSTAL#923,INDDIRCOB#924,INDDIRDESP#925,CELULAR#926,RADIO#927,INDEXONERADO#928,REFERDIREC#929,REFERDIRECTRAB#930,TELEXTRABAJO#931,INDTELEX#932,SEGCOMP#933,EMAILFACTELEC#934,EMAILFACTELECCC#935,UPLOAD_BLOCK_PROCESS#936,UPLOAD_PROCESS_DATE#937,FILENAME#938,REFEXTERNA#939] csv\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-94df9b6488ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;31m# generate index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iDX\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonically_increasing_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_uniqueid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IDX\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left_outer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIDX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIDX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0mdf_unique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-94df9b6488ce>\u001b[0m in \u001b[0;36mgenerate_uniqueid\u001b[0;34m(spark, df, last_id)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mtotal_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IDX\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mtotal_rows\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \"\"\"\n\u001b[0;32m-> 1202\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/conda/envs/env_python27/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: u\"cannot resolve '`IDX`' given input columns: [];;\\n'Project ['IDX]\\n+- AnalysisBarrier\\n      +- Project\\n         +- Project [Op#872, TIPOID#873, NUMID#874, DVID#875, NOMTER#876, APETER#877, CODPAIS#878, CODESTADO#879, CODCIUDAD#880, CODMUNICIPIO#881, DIREC#882, TELEF1#883, TELEF2#884, TELEF3#885, FAX#886, TELEX#887, ZIP#888, INDNACIONAL#889, STSTER#890, FECSTS#891, NUMCTAAUXI#892, TIPOTER#893, MIGRADO#894, APEMATTER#895, NOMCENTRAB#896, DIRECTRAB#897, CODPAISTRAB#898, CODESTADOTRAB#899, CODCIUDADTRAB#900, CODMUNICIPIOTRAB#901, TELEF1TRAB#902, TELEF2TRAB#903, ANEXOTRAB#904, FAXTRAB#905, CODZONAPOSTALTRAB#906, NACIONALIDAD#907, NOMCORREO#908, ZONACOB#909, SITLAB#910, PROFESION#911, TAMEMPRESA#912, SEXO#913, FECNAC#914, FECCREA#915, USUCREA#916, FECMOD#917, USUMOD#918, ESTCIVIL#919, INDASEGVIDA#920, CODACT#921, CIIU#922, CODZONAPOSTAL#923, INDDIRCOB#924, INDDIRDESP#925, CELULAR#926, RADIO#927, INDEXONERADO#928, REFERDIREC#929, REFERDIRECTRAB#930, TELEXTRABAJO#931, INDTELEX#932, SEGCOMP#933, EMAILFACTELEC#934, EMAILFACTELECCC#935, UPLOAD_BLOCK_PROCESS#936, UPLOAD_PROCESS_DATE#937, FILENAME#938, REFEXTERNA#939, monotonically_increasing_id() AS iDX#1008L]\\n            +- Relation[Op#872,TIPOID#873,NUMID#874,DVID#875,NOMTER#876,APETER#877,CODPAIS#878,CODESTADO#879,CODCIUDAD#880,CODMUNICIPIO#881,DIREC#882,TELEF1#883,TELEF2#884,TELEF3#885,FAX#886,TELEX#887,ZIP#888,INDNACIONAL#889,STSTER#890,FECSTS#891,NUMCTAAUXI#892,TIPOTER#893,MIGRADO#894,APEMATTER#895,NOMCENTRAB#896,DIRECTRAB#897,CODPAISTRAB#898,CODESTADOTRAB#899,CODCIUDADTRAB#900,CODMUNICIPIOTRAB#901,TELEF1TRAB#902,TELEF2TRAB#903,ANEXOTRAB#904,FAXTRAB#905,CODZONAPOSTALTRAB#906,NACIONALIDAD#907,NOMCORREO#908,ZONACOB#909,SITLAB#910,PROFESION#911,TAMEMPRESA#912,SEXO#913,FECNAC#914,FECCREA#915,USUCREA#916,FECMOD#917,USUMOD#918,ESTCIVIL#919,INDASEGVIDA#920,CODACT#921,CIIU#922,CODZONAPOSTAL#923,INDDIRCOB#924,INDDIRDESP#925,CELULAR#926,RADIO#927,INDEXONERADO#928,REFERDIREC#929,REFERDIRECTRAB#930,TELEXTRABAJO#931,INDTELEX#932,SEGCOMP#933,EMAILFACTELEC#934,EMAILFACTELECCC#935,UPLOAD_BLOCK_PROCESS#936,UPLOAD_PROCESS_DATE#937,FILENAME#938,REFEXTERNA#939] csv\\n\""
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import boto3\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UnicodeWarning)\n",
    "\n",
    "is_prod = False\n",
    "\n",
    "if is_prod:\n",
    "    from awsglue.utils import getResolvedOptions\n",
    "    from pyspark.context import SparkContext\n",
    "    from awsglue.context import GlueContext\n",
    "    from awsglue.job import Job\n",
    "\n",
    "    is_prod = True\n",
    "    args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
    "    sc = SparkContext()\n",
    "    glueContext = GlueContext(sc)\n",
    "    spark = glueContext.spark_session\n",
    "    job = Job(glueContext)\n",
    "    job.init(args['JOB_NAME'], args)\n",
    "\n",
    "else:\n",
    "    from pyspark.context import SparkContext\n",
    "    from pyspark.sql import SparkSession\n",
    "\n",
    "    os.environ['PYSPARK_SUBMIT_ARGS'] = \"--packages=org.apache.hadoop:hadoop-aws:2.7.3,\" \\\n",
    "                                        \"$SPARK_HOME/jars/com.amazonaws_aws-java-sdk-s3-1.10.6.jar\"\n",
    "\n",
    "    s3_schema = \"s3a://\"\n",
    "    access_id = \"xxx\"\n",
    "    access_key = \"xxx\"\n",
    "    bucket_name = \"aws-datalake-testing\"\n",
    "\n",
    "    spark = SparkSession.builder.appName(\"APP_4\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", access_id) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", access_key) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.fast.upload\", \"true\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "\n",
    "file_empty = \"\"\n",
    "my_path = '/folder/json/'\n",
    "s3, my_bucket = session_bucket(bucket_name, access_id, access_key)\n",
    "\n",
    "path_block = \"{0}{1}/{2}{3}/\".format(s3_schema, bucket_name, my_path)\n",
    "\n",
    "df_load = spark.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .load(path_block)\n",
    "print(df_load.printSchema())\n",
    "   \n",
    "\n",
    "if is_prod:\n",
    "    job.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_load.withColumn(\"iDX\", F.monotonically_increasing_id().cast(\"string\")).select([c for c in df_load.columns + [\"IDX\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2, total_rows  = generate_uniqueid(spark, df1, last_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1.join(df2, \"IDX\", \"left_outer\").drop(df1.IDX).drop(df2.IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------+----+------+-------+-------+---------+---------+------------+--------------------+-------+------+------+----+-----+---+-----------+------+-------------------+--------------+-------+-------+-----------+----------+--------------------+-----------+-------------+-------------+----------------+----------+----------+---------+-------+-----------------+------------+--------------+-------+------+---------+----------+----+-------------------+-------------------+------------+------+------+--------+-----------+------+----+-------------+---------+----------+-------+-----+------------+----------+--------------+------------+--------+-------+-------------+---------------+--------------------+-------------------+------------------+----------+--------+\n",
      "| Op|TIPOID|   NUMID|DVID|NOMTER| APETER|CODPAIS|CODESTADO|CODCIUDAD|CODMUNICIPIO|               DIREC| TELEF1|TELEF2|TELEF3| FAX|TELEX|ZIP|INDNACIONAL|STSTER|             FECSTS|    NUMCTAAUXI|TIPOTER|MIGRADO|  APEMATTER|NOMCENTRAB|           DIRECTRAB|CODPAISTRAB|CODESTADOTRAB|CODCIUDADTRAB|CODMUNICIPIOTRAB|TELEF1TRAB|TELEF2TRAB|ANEXOTRAB|FAXTRAB|CODZONAPOSTALTRAB|NACIONALIDAD|     NOMCORREO|ZONACOB|SITLAB|PROFESION|TAMEMPRESA|SEXO|             FECNAC|            FECCREA|     USUCREA|FECMOD|USUMOD|ESTCIVIL|INDASEGVIDA|CODACT|CIIU|CODZONAPOSTAL|INDDIRCOB|INDDIRDESP|CELULAR|RADIO|INDEXONERADO|REFERDIREC|REFERDIRECTRAB|TELEXTRABAJO|INDTELEX|SEGCOMP|EMAILFACTELEC|EMAILFACTELECCC|UPLOAD_BLOCK_PROCESS|UPLOAD_PROCESS_DATE|          FILENAME|REFEXTERNA|UNIQUEID|\n",
      "+---+------+--------+----+------+-------+-------+---------+---------+------------+--------------------+-------+------+------+----+-----+---+-----------+------+-------------------+--------------+-------+-------+-----------+----------+--------------------+-----------+-------------+-------------+----------------+----------+----------+---------+-------+-----------------+------------+--------------+-------+------+---------+----------+----+-------------------+-------------------+------------+------+------+--------+-----------+------+----+-------------+---------+----------+-------+-----+------------+----------+--------------+------------+--------+-------+-------------+---------------+--------------------+-------------------+------------------+----------+--------+\n",
      "|  I|     0|16443831|   0|JAVIER|HUAYLLA|    428|      015|      001|         034|AV. AV. CIRCUNVAL...|0000000|  null|  null|null| null|L30|          N|   VAL|2017-03-07 02:50:50|00000016443831|      P|      M|YANAHUILLCA|      null|AV. AV. CIRCUNVAL...|        428|          015|          001|             034|      null|      null|     null|   null|              L30|        PERU|Javier Huaylla|    046|  null|    00000|      null|   M|1986-06-28 00:00:00|2017-03-07 02:50:50|DBL_BDRSA_01|  null|  null|    null|          0|  null|null|          L30|        D|         D|   null| null|        null|      null|          null|        null|    null|   null|         null|           null|                  01|2018-10-25 22:18:43|19000101-010000000|  16443831| 2420329|\n",
      "+---+------+--------+----+------+-------+-------+---------+---------+------------+--------------------+-------+------+------+----+-----+---+-----------+------+-------------------+--------------+-------+-------+-----------+----------+--------------------+-----------+-------------+-------------+----------------+----------+----------+---------+-------+-----------------+------------+--------------+-------+------+---------+----------+----+-------------------+-------------------+------------+------+------+--------+-----------+------+----+-------------+---------+----------+-------+-----+------------+----------+--------------+------------+--------+-------+-------------+---------------+--------------------+-------------------+------------------+----------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uniqueid(spark, df, last_id):\n",
    "    result_list = list()\n",
    "    count = 0 + int(last_id)\n",
    "    total_rows = 0\n",
    "    for row in df.select(\"IDX\").collect():\n",
    "        count += 1\n",
    "        total_rows += 1\n",
    "        result_dict = Row(IDX=str(row[\"IDX\"]), UNIQUEID=\"{0}\".format(count))\n",
    "        result_list.append(result_dict)\n",
    "    df2 = spark.createDataFrame(result_list)\n",
    "    return df2, total_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = spark.read.parquet(\"s3a://aws-datalake-testing/BDAX/APP_DMS/POLIZA/LZN/01/01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv6 =df_load.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesA = [('Pirate',1),('Monkey',2),('Ninja',3),('Spaghetti',4)]\n",
    "TableA = spark.createDataFrame(valuesA,['name','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = TableA.withColumn(\"IDX\", F.monotonically_increasing_id().cast(\"string\"))\n",
    "df2, total_rows = generate_uniqueid(spark, df1, last_id)\n",
    "df_join = df1.join(df2, \"IDX\", \"left_outer\").drop(df2.IDX).drop(df1.IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+--------+\n",
      "|     name| id|UNIQUEID|\n",
      "+---------+---+--------+\n",
      "|   Monkey|  2| 2410234|\n",
      "|   Pirate|  1| 2410233|\n",
      "|Spaghetti|  4| 2410236|\n",
      "|    Ninja|  3| 2410235|\n",
      "+---------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
